Introduction
============

Generating samples from a posterior distribution is a fundamental task in Bayesian inference. Development of sampling-based algorithms of the Markov chain Monte Carlo family in the mid-eighties :cite:p:`geman1984stochastic` have made such task accessible for the solution of Bayesian inverse problems to a wide audience of both researchers and practitioners. However, the number of samples required by these approaches is typically significant and the convergence of Markov chains to their stationary distribution is not always easy to quantify, even if a number of metrics have been proposed in the literature over the years.

More recent paradigms have been proposed in the context of variational inference :cite:p:`wainwright2008graphical`, where an optimization problem is formulated to determine the optimal member of a parametric family of distributions that can approximate a target posterior density. In addition, flexible approaches to parametrize variational distributions through a composition of transformations (closely related to the concept of trasport maps, see, e.g., :cite:p:`villani2009optimal`) have reached popularity under the name of **normalizing flows** :cite:p:`kobyzev2020normalizing, papamakarios2021normalizing`. The combination of variational inference and normalizing flow has received significant recent interest in the context of general algorithm for the solution of inverse problems :cite:p:`rezende2015variational`.

However, cases where the computational cost of evaluating the underlying statistical model is significant occur quite often in engineering and applied sciences, for example when such evaluation requires the solution of an ordinary or partial differential equation. In such cases, inference can easily become intractable. Additionally, strong and nonlinear dependence between model parameters may results in difficult-to-sample posterior distributions characterized by features at multiple scales or by multiple modes. The LINFA library is specifically designed for cases where the model evaluation is computationally expensive. In such cases, the construction of an adaptively trained surrogate model is key to reduce the computational cost of inference. In addition, LINFA provides adaptive annealing schedulers, where temperature increments are automatically determined based on the available variational approximant of the posterior distribution. Thus, adaptive annealing makes it easier to sample from complicated densities.
