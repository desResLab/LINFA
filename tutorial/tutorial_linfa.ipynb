{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINFA Tutorial\n",
    "This LINFA tutorial will guide through the definition of each of the quantities and functions of LINFA by applying LINFA to a practical problem set.\n",
    "<br>\n",
    "\n",
    "* **What is LINFA?**\n",
    "<br> \n",
    "    LINFA is a library for variational inference with normalizing flow and adaptive annealing. LINFA accommodates computationally expensive models and difficult-to-sample posterior distributions with dependent parameters.\n",
    "* **Why use LINFA?**\n",
    "<br>\n",
    "    Designed as a general inference engine, LINFA allows the user to define custom input transformations, computational models, surrogates, and likelihood functions which will be discussed throughout the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial outline\n",
    "In this tutorial we will:\n",
    "1. Define the model (problem set) to apply functions and quantities supported by LINFA.\n",
    "2. Check if the model gradients computed by PyTorch match with simple finite difference-based approximations.\n",
    "3. Model evaluation set up process and applications:\n",
    "    * Application 1: Variational inference with the original model.\n",
    "    * Application 2: Variational inference with neural network surrogate model.\n",
    "\n",
    "After going through this tutorial, users should be able to define and integrate their model with LINFA, and use the various features provided by LINFA to perform variational inference.\n",
    "<br>\n",
    "\n",
    "In addition, we emphasize two special features available through LINFA:\n",
    "* Adaptively trained surrogate models (NoFAS module).\n",
    "* Adaptive annealing schedulers (AdaAnn module).\n",
    "\n",
    "We encourage the user to take advantage of such modules, especially when using physics-based models with computationally expensive evaluations. It relieves the need of heavy computations such as gradient calculation directly through the model which reduces computational cost of inference, particularly for difficult-to-sample distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "#### Background theory and examples for LINFA\n",
    "* Y. Wang, F. Liu and D.E. Schiavazzi, Variational Inference with NoFAS: Normalizing Flow with Adaptive Surrogate for Computationally Expensive Models: https://www.sciencedirect.com/science/article/abs/pii/S0021999122005162\n",
    "* E.R. Cobian, J.D. Hauenstein, F. Liu and D.E. Schiavazzi, AdaAnn: Adaptive Annealing Scheduler for Probability Density Approximation:\n",
    "https://www.dl.begellhouse.com/journals/52034eb04b657aea,796f39cb1acf1296,6f85fe1149ff41d9.html?sgstd=1\n",
    "\n",
    "\n",
    "#### More about LINFA library: \n",
    "* LINFA library [documentation](https://linfa-vi.readthedocs.io/en/latest/index.html).\n",
    "* LINFA GitHub [repository](https://github.com/desResLab/LINFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries ##\n",
    "import os\n",
    "from linfa.run_experiment import experiment\n",
    "from linfa.transform import Transformation\n",
    "from linfa.nofas import Surrogate\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem definition\n",
    "* Our physics-based model **phys** consists of a simple ballistic model. We would like to compute the quantities: \n",
    "    * maximum height (m) $x_{1}$,\n",
    "    * final landing location (m) of the object $x_{2}$,\n",
    "    * total flight time (s)  $x_{2}$,\n",
    "    \n",
    "    from the inputs:\n",
    "    * starting position (m) $z_{1}$,\n",
    "    * initial velocity (m/s)  $z_{2}$,\n",
    "    * angle (degrees) $z_{3}$.\n",
    "<br>\n",
    "\n",
    "The model is described by the following equations\n",
    "$$\n",
    "x_{1} = \\frac{z_{2}^{2}\\,\\sin^{2}(z_{3})}{2\\,g},\\,\\,\n",
    "x_{2} = z_{1} + \\frac{z_{2}^{2}\\,\\sin(2\\,z_{3})}{g},\\,\\,\n",
    "x_{3} = \\frac{2\\,z_{2}\\,\\sin(z_{3})}{g}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model identifiability\n",
    "\n",
    "By considering fixed values for the outputs $(x_{1},x_{2},x_{3}) = (\\widetilde{x}_{1},\\widetilde{x}_{2},\\widetilde{x}_{3})$, we can perform some algebraic manipulation. For example if we derive $z_{2}$ from the equation for $x_{3}$ and we plug it back in the equation for $x_{1}$, we get the equation\n",
    "$$\n",
    "g\\,\\frac{\\widetilde{x}_{3}^{2}}{8} = \\widetilde{x}_{1}^{2}.\n",
    "$$\n",
    "\n",
    "This suggests the maximum height and time of flight are, as expected, related by a deterministic condition and therefore only one of these provide an independent information for the solution of the inverse problem. \n",
    "\n",
    "Due to this relation, the number of observables is reduced to only two, from three inputs. This results in a non-identifiable inference task. In other words, there is an infinite number of input combinations $(z_{1},z_{2},z_{3})$ corresponding to the outputs $(\\widetilde{x}_{1},\\widetilde{x}_{2},\\widetilde{x}_{3})$. \n",
    "\n",
    "A graphical explanation for this lack of identifiability can be is shown in the the plot below\n",
    "\n",
    "<img src=\"./imgs/trajectories.png\" width=\"800px\" aligned=\"center\"><br>\n",
    "Examples of trajectories resulting in the same landing distance and maximum height (or time of flight).\n",
    "\n",
    "This picture shows how the final target location at $x_{2}$ can be reached by multiple initial positions, velocities and angles. The lack of indetifiability also translates in the existence of a one-dimensional manifold of inputs that correspond to the same outputs. This manifold can be determined from the following expressions for the relations $z_1(z_{3})$ and $z_2(z_{3})$ \n",
    "$$\n",
    "z_{1} = \\widetilde{x}_{2} - \\frac{g\\cdot \\widetilde{x}_{3}^{2}}{2}\\cdot \\left[\\frac{\\cos(z_{3})}{\\sin(z_{3})}\\right],\\,\\,\n",
    "z_{2} = \\frac{g\\cdot \\widetilde{x}_{3}}{2\\,\\sin(z_{3})}.\n",
    "$$\n",
    "These two curves are also plotted below.\n",
    "\n",
    "<img src=\"./imgs/non_ident.png\" width=\"800px\" aligned=\"center\"><br>\n",
    "Two-dimensional projections of one-dimensional manifold where all parameters correspond to the same outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation as a Python class\n",
    "\n",
    "* We now create a new **Phys** model class, having three member functions:\n",
    "    * `__init__`: A constructor.\n",
    "    * `genDataFile`: A member function to create synthetic observations.\n",
    "    * `solve_t`: A function to perform forward model evaluations.\n",
    "    * *Please refer to the comments below for additional implementation details.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Implementation of the traditional trajectory motion physics problem ####\n",
    "class Phys:\n",
    "    \n",
    "    ### Define constructor function for Phys class ###\n",
    "    def __init__(self):\n",
    "        ## Define input parameters (True value)  \n",
    "        # input[] = [starting_position, initial_velocity, angle] = [1(m), 5(m/s), 60(degs)]\n",
    "        self.defParam = torch.Tensor([[1.0, 5.0, 60.0]])\n",
    "\n",
    "        self.gConst = 9.81   # gravitational constant\n",
    "        self.stdRatio = 0.05 # standard deviation ratio\n",
    "        self.data = None     # data set of model sample\n",
    "\n",
    "    ### Define data file generator function ###\n",
    "    # dataSize (int): size of sample (data)\n",
    "    # dataFileName (String): name of the sample data file\n",
    "    # store (Boolean): True if user wish to store the generated data file; False otherwise.\n",
    "    def genDataFile(self, dataSize = 50, dataFileName=\"data_phys.txt\", store=True):\n",
    "        def_out = self.solve_t(self.defParam)[0]\n",
    "        print(def_out)\n",
    "        self.data = def_out + self.stdRatio * torch.abs(def_out) * torch.normal(0, 1, size=(dataSize, 3))\n",
    "        self.data = self.data.t().detach().numpy()\n",
    "        if store: np.savetxt(dataFileName, self.data)\n",
    "        return self.data\n",
    "\n",
    "    ### Define data file generator function ###\n",
    "    # params (Tensor): input parameters storing starting position, initial velocity, and angle in corresponding order.\n",
    "    def solve_t(self, params):\n",
    "        z1, z2, z3 = torch.chunk(params, chunks=3, dim=1) # input parameters\n",
    "        z3 = z3 * (np.pi / 180)                           # convert unit from degree to radians\n",
    "        \n",
    "        ## Output value calculation\n",
    "        # ouput[] = [maximum_height, final_location, total_time]\n",
    "        x = torch.cat(( (z2 * z2 * torch.sin(z3) * torch.sin(z3)) / (2.0 * self.gConst),  # x1: maxHeight\n",
    "            z1 + ((z2 * z2 * torch.sin(2.0 * z3)) / self.gConst),                         # x2: finalLocation \n",
    "            (2.0 * z2 * torch.sin(z3)) / self.gConst), 1)                                 # x3: totalTime\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate phys sample file ##\n",
    "\n",
    "# Define model\n",
    "model = Phys()\n",
    "\n",
    "# Generate Data\n",
    "physData = model.genDataFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model set up, we go on to our second step, i.e., *Calculating the gradient to confirm model functionality.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Gradient Calculation\n",
    "* Prior to applying NOFAS to our Phys model, we check if the model gradient (Jacobian actually since it has multiple outputs) is correctly computed by PyTorch. \n",
    "* Specifically, when the surrogate is not enabled, gradient calculation is completed straight through the model, so we want to ensure that this is correct before running some inference task.\n",
    "* Here we compute each gradient using (1) Pytorch and (2) a finite difference (Euler forward differences) approximation, and compare the results provided by these two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Computing gradients through PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Implementation of gradient calculation using PyTorch - version 2 #### \n",
    "class PytorchGrad2: \n",
    "    ### Define constructor function for PytorchGrad2 class ###\n",
    "    def __init__(self, model, transform):\n",
    "        # Define input parameters and enable gradient calculation\n",
    "        self.z = torch.Tensor([[1.0, 5.0, 60.0]])\n",
    "        self.z.requires_grad = True\n",
    "        \n",
    "        self.in_vals = transform.forward(self.z)\n",
    "\n",
    "        self.out_val = model.solve_t(self.in_vals)\n",
    "        self.out1, self.out2, self.out3 = torch.chunk(self.out_val, chunks=3, dim=1)\n",
    "\n",
    "    # Compute gradients using backward function for y\n",
    "    def back_x1(self): \n",
    "        self.out1.backward()\n",
    "        d1 = self.in_vals.grad\n",
    "        a, b, c = torch.chunk(d1, chunks=3, dim=1)\n",
    "        return [a, b, c]\n",
    "    \n",
    "    def back_x2(self): \n",
    "        self.out2.backward()\n",
    "        d2 = self.in_vals.grad\n",
    "        a, b, c = torch.chunk(d2, chunks=3, dim=1)\n",
    "        return [a, b, c]\n",
    "    \n",
    "    def back_x3(self): \n",
    "        self.out3.backward()\n",
    "        d3 = self.in_vals.grad\n",
    "        a, b, c = torch.chunk(d3, chunks=3, dim=1)\n",
    "        return [a, b, c]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Phys model\n",
    "model = Phys()\n",
    "# Set transformation information and define transforamtion\n",
    "trsf_info = [['identity',0.0,0.0,0.0,0.0],\n",
    "             ['identity',0,0.0,0.0,0.0],\n",
    "             ['identity',0,0.0,0.0,0.0]]\n",
    "        \n",
    "transform = Transformation(trsf_info)\n",
    "\n",
    "# List to store dx/dz values\n",
    "dx_dz_pytorch2 = []\n",
    "\n",
    "# Define PytorchGrad object and calculate gradient\n",
    "pyGrad2 = PytorchGrad2(model, transform)\n",
    "dx_dz_pytorch2.append(pyGrad2.back_x1())\n",
    "\n",
    "pyGrad2 = PytorchGrad2(model, transform)\n",
    "dx_dz_pytorch2.append(pyGrad2.back_x2())\n",
    "\n",
    "pyGrad2 = PytorchGrad2(model, transform)\n",
    "dx_dz_pytorch2.append(pyGrad2.back_x3())\n",
    "\n",
    "# print(dx_dz_pytorch2) # check if output matches expectations\n",
    "\n",
    "# convert to pandas DataFrame for readability\n",
    "jacob_mat_2 = pd.DataFrame(dx_dz_pytorch2.numpy(), columns=['dz1', 'dz2', 'dz3'])\n",
    "jacob_mat_2.index = ['dx1', 'dx2', 'dx3']\n",
    "jacob_mat_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximating gradients with finite differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that manually calculates a derivative ###\n",
    "def getGrad(f_eps, f, eps):\n",
    "    return (f_eps - f) / (eps)\n",
    "\n",
    "### Function that returns a list of gradients ###\n",
    "def gradList(f_eps1, f_eps2, f_eps3, f, eps): \n",
    "    return [getGrad(f_eps1, f, eps), getGrad(f_eps2, f, eps), getGrad(f_eps3, f, eps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store dx/dz values\n",
    "dx_dz = []\n",
    "dx1_dz = []\n",
    "dx2_dz = []\n",
    "dx3_dz = []\n",
    "\n",
    "# Set up parameters\n",
    "eps = 1.0\n",
    "z = torch.Tensor([[1.0, 5.0, 60.0]])\n",
    "z_eps1 = torch.Tensor([[1.0 + eps, 5.0, 60.0]])\n",
    "z_eps2 = torch.Tensor([[1.0, 5.0 + eps, 60.0]])\n",
    "z_eps3 = torch.Tensor([[1.0, 5.0, 60.0 + eps]])\n",
    "\n",
    "x1_eps1 = model.solve_t(z_eps1)[0,0]\n",
    "x1_eps2 = model.solve_t(z_eps2)[0,0]\n",
    "x1_eps3 = model.solve_t(z_eps3)[0,0]\n",
    "x1_eps = model.solve_t(z)[0,0]\n",
    "\n",
    "dx1_dz = gradList(x1_eps1, x1_eps2, x1_eps3, x1_eps, eps)\n",
    "dx_dz.append(dx1_dz)\n",
    "\n",
    "x2_eps1 = model.solve_t(z_eps1)[0,1]\n",
    "x2_eps2 = model.solve_t(z_eps2)[0,1]\n",
    "x2_eps3 = model.solve_t(z_eps3)[0,1]\n",
    "x2_eps = model.solve_t(z)[0,1]\n",
    "\n",
    "dx2_dz = gradList(x2_eps1, x2_eps2, x2_eps3, x2_eps, eps)\n",
    "dx_dz.append(dx2_dz)\n",
    "\n",
    "x3_eps1 = model.solve_t(z_eps1)[0,2]\n",
    "x3_eps2 = model.solve_t(z_eps2)[0,2]\n",
    "x3_eps3 = model.solve_t(z_eps3)[0,2]\n",
    "x3_eps = model.solve_t(z)[0,2]\n",
    "\n",
    "dx3_dz = gradList(x3_eps1, x3_eps2, x3_eps3, x3_eps, eps)\n",
    "dx_dz.append(dx3_dz)\n",
    "\n",
    "# print(dx_dz) # check if values match expected outputs\n",
    "\n",
    "# convert to pandas DataFrame for readability\n",
    "jacob_mat_3 = pd.DataFrame(dx_dz, columns=['dz1', 'dz2', 'dz3'])\n",
    "jacob_mat_3.index = ['dx1', 'dx2', 'dx3']\n",
    "jacob_mat_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We verify the convergence for the finite difference approximation to the PyTorch gradient for dx2_dz3\n",
    "- Note: adjust values to check convergence for other gradients of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Focus: dx2_dz3\n",
    "\n",
    "initial_eps = 15        # Initial change of value (eps)\n",
    "k = 150                 # Number of iterations\n",
    "dx2_dz3_list = []       # List to store results\n",
    "pytorch_grad2 = -0.0445 # Pytorch gradient value\n",
    "\n",
    "# Calculate for dx2_dz3 as eps decreases\n",
    "for t in range(1, k):\n",
    "    update_eps = initial_eps*(1/t)                             # updated eps value\n",
    "    z_eps3 = torch.Tensor([[1.0, 5.0, 60.0 + update_eps]])     # update z_eps3\n",
    "    x2_eps3 = model.solve_t(z_eps3)[0,1]                       # update x2_eps3\n",
    "    dx2_dz3_list.append(getGrad(x2_eps3, x2_eps, update_eps))  # store result to dx2_dz3_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot result to see convergence\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1,k), dx2_dz3_list, c = \"red\", linestyle = \"solid\", label = \"Model Gradient\")\n",
    "\n",
    "plt.axhline(y = pytorch_grad2, color = 'blue', linestyle = '-', label = \"Pytorch Gradient-2\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Gradient Plot for dx2_dz3\")\n",
    "plt.ylabel(\"Gradient\")\n",
    "plt.xlabel(\"k-Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we confirmed that our model successfully computes the gradients, we go on to our third step: *Model Evaluation Set Up and Applications*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational inference with full model\n",
    "\n",
    "#### Definition of hyperparameters\n",
    "The first step is to define all options and hyperparameters for the inference task. Additional detail for each hyperparameter can be found in the [documentation](https://linfa-vi.readthedocs.io/en/latest/content/linfa_options.html) or in the definition of the [experiment](https://github.com/desResLab/LINFA/blob/master/linfa/run_experiment.py) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Setting\n",
    "exp = experiment()\n",
    "exp.flow_type        = 'maf'        # str: Type of flow\n",
    "exp.n_blocks         = 5            # int: Number of layers                            \n",
    "exp.hidden_size      = 100          # int: Hidden layer size for MADE in each layer  \n",
    "exp.n_hidden         = 1            # int: Number of hidden layers in each MADE      \n",
    "exp.activation_fn    = 'relu'       # str: Actication function used                  \n",
    "exp.input_order      = 'sequential' # str: Input order for create_mask           \n",
    "exp.batch_norm_order = True         # boolean: Order to decide if batch_norm is used    \n",
    "exp.save_interval    = 5000         # int: How often to sample from normalizing flow\n",
    "\n",
    "exp.input_size    = 3               # int: Dimensionality of input                   \n",
    "exp.batch_size    = 250             # int: Number of samples generated             \n",
    "exp.true_data_num = 2               # double: number of true model evaluated      \n",
    "exp.n_iter        = 25001           # int: Number of iterations                      \n",
    "exp.lr            = 0.01            # float: Learning rate                              \n",
    "exp.lr_decay      = 0.9999          # float: Learning rate decay                \n",
    "exp.log_interval  = 100             # int: How often to show loss stat   \n",
    "\n",
    "exp.run_nofas          = False      # boolean: to run experiment with nofas\n",
    "exp.annealing          = False      # boolean: to run experiment with annealing\n",
    "exp.calibrate_interval = 1000       # int: How often to update surrogate model     \n",
    "exp.budget             = 260        # int: Total number of true model evaluation\n",
    "\n",
    "exp.surr_pre_it  = 20000            # int: Number of pre-training iterations for surrogate model\n",
    "exp.surr_upd_it  = 6000             # int: Number of iterations for the surrogate model update\n",
    "exp.surr_folder  = \"./\"\n",
    "exp.use_new_surr = True             # boolean: to run experiment with nofas\n",
    "\n",
    "exp.results_file = 'results.txt'      # str: result text file name\n",
    "exp.log_file     = 'log.txt'          # str: log text file name\n",
    "exp.samples_file = 'samples.txt'      # str: sample text file name\n",
    "exp.seed         = random.randint(0, 10 ** 9)  # int: Random seed used\n",
    "exp.n_sample     = 5000               # int: Total number of iterations\n",
    "exp.no_cuda      = True               # boolean: to run experiment with NO cuda\n",
    "\n",
    "exp.optimizer    = 'RMSprop'          # str: Type of optimizer\n",
    "exp.lr_scheduler = 'ExponentialLR'    # str: Type of scheduler\n",
    "\n",
    "exp.device = torch.device('cuda:0' if torch.cuda.is_available() and not exp.no_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the transformation \n",
    "Now we define the trasformation of parameters and initialize the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation based on normalization rate\n",
    "trsf_info = [['identity',0.0,0.0,0.0,0.0],\n",
    "             ['identity',0.0,0.0,0.0,0.0],\n",
    "             ['linear',-3,3,30.0,80.0]]\n",
    "trsf = Transformation(trsf_info)        \n",
    "exp.transform = trsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model and surrogate definition\n",
    "We create an instance of the **Phys** model and assign `None` to the surrogate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Phys()\n",
    "exp.model = model\n",
    "\n",
    "# Get data\n",
    "model.data = np.loadtxt('./data_phys.txt')\n",
    "\n",
    "# Run experiment without surrogate\n",
    "exp.surrogate = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-likelihood definiton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define log density\n",
    "# x: original, untransformed inputs\n",
    "# model: our model\n",
    "# transform: our transformation \n",
    "def log_density(x, model, surrogate, transform):\n",
    "    # x contains the original, untransformed inputs\n",
    "    np.savetxt(exp.output_dir + '/' + exp.name + '_x', x.detach().numpy(), newline=\"\\n\")\n",
    "    # Compute transformation log Jacobian\n",
    "    adjust = transform.compute_log_jacob_func(x)\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    # Get the absolute values of the standard deviations\n",
    "    stds = torch.abs(model.solve_t(model.defParam)) * model.stdRatio\n",
    "    Data = torch.tensor(model.data).to(exp.device)\n",
    "    \n",
    "    # Check for surrogate\n",
    "    if surrogate:\n",
    "        modelOut = exp.surrogate.forward(x)\n",
    "    else:\n",
    "        modelOut = model.solve_t(transform.forward(x))\n",
    "\n",
    "    # Eval LL\n",
    "    ll1 = -0.5 * np.prod(model.data.shape) * np.log(2.0 * np.pi)\n",
    "    ll2 = (-0.5 * model.data.shape[1] * torch.log(torch.prod(stds))).item()\n",
    "    ll3 = 0.0\n",
    "    for i in range(3):\n",
    "        ll3 += - 0.5 * torch.sum(((modelOut[:, i].unsqueeze(1) - Data[i, :].unsqueeze(0)) / stds[0, i]) ** 2, dim=1)\n",
    "    negLL = -(ll1 + ll2 + ll3)\n",
    "    res = -negLL.reshape(x.size(0), 1) + adjust\n",
    "    np.savetxt(exp.output_dir + '/' + exp.name + '_res', res.detach().numpy(), newline=\"\\n\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch inference task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run \n",
    "print('')\n",
    "print('--- Temporary TEST: Physics Example - without NOFAS')\n",
    "print('')\n",
    "\n",
    "print('--- Running on device: '+ str(exp.device))\n",
    "print('')\n",
    "\n",
    "# Experiment Setting\n",
    "exp.name = \"phys_nofasFree\"           # str: Name of experiment\n",
    "exp.output_dir   = './' + exp.name    # str: output directory location\n",
    "\n",
    "# Assign logdensity\n",
    "exp.model_logdensity = lambda x: log_density(x, model, exp.surrogate, trsf)\n",
    "\n",
    "# Run VI\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model evaluation has been successfully completed by checking at the newly created **phys_nofasFree** folder in our current directory.\n",
    "Note also that LINFA supports a post processing script to plot all results which includes plots of log loss, parameter estimation, and estimated output data.\n",
    "\n",
    "The according code line is: `python -m linfa.plot_res -n phys_nofasFree -i 25000 -f phys_nofasFree`\n",
    "    \n",
    "> However, even with our simple model, computing the gradients and confirming model functionality everytime before applying the model evaluation is time consuming and when it comes with evaluting even more complex models, the computational costs will be exponential and will likely result in intractable inference. <br>\n",
    "In such cases, LINFA enables the construction of the adaptively trained surrogate model which resolves such concerns regarding the computational cost of inference. By utilizing the surrogate model, gradient computation is executed by the surrogate model which eliminates the need to manually check for gradient calcultation. <br>\n",
    "In addition, LINFA provides an adaptive annealing scheduler which allows easier sampling from complicated densities. <br>\n",
    "\n",
    "> Accordingly, we will specifically observe how the adaptively trained surrogate model relieves compuatational cost while ensuring inference in our last step: <br>\n",
    "*Applying our model including the Surrogate model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "The results below are obtained from variational inference with the full model. The posterior distribution is concentrated around the one-dimensional manifold where the input parameters are not identifiable. \n",
    "\n",
    "<img src=\"./imgs/orig_log.png\" width=\"300px\" aligned=\"center\"><br>\n",
    "Loss converge profiles for variational inference with the full model.<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"./imgs/orig_params_1.png\" width=\"300px\" aligned=\"center\">\n",
    "<img src=\"./imgs/orig_params_2.png\" width=\"300px\" aligned=\"center\">\n",
    "<img src=\"./imgs/orig_params_3.png\" width=\"300px\" aligned=\"center\"><br>\n",
    "Posterior distribution of the input parameters.<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"./imgs/orig_data_1.png\" width=\"300px\" aligned=\"center\">\n",
    "<img src=\"./imgs/orig_data_2.png\" width=\"300px\" aligned=\"center\">\n",
    "<img src=\"./imgs/orig_data_3.png\" width=\"300px\" aligned=\"center\"><br>\n",
    "Comparison between posterior predictive distribution and available observations.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"./samples/simple3.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Phys Model with the Adaptively Trained Surrogate Model\n",
    "Note: this block of code takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Setting\n",
    "exp.name = \"phys\"      # str: Name of experiment\n",
    "exp.output_dir   = './' + exp.name    # str: output directory location\n",
    "\n",
    "# Define model\n",
    "model = Phys()\n",
    "exp.model = model\n",
    "\n",
    "# Get data\n",
    "model.data = np.loadtxt('./data_phys.txt')\n",
    "\n",
    "# Define surrogate\n",
    "exp.surrogate = Surrogate(exp.name, lambda x: model.solve_t(trsf.forward(x)), exp.input_size, 3, \n",
    "                          model_folder=exp.surr_folder, limits=torch.Tensor([[0, 2], [0, 10], [-3, 3]]), \n",
    "                          memory_len=20, device=exp.device)\n",
    "surr_filename = exp.surr_folder + exp.name\n",
    "if exp.use_new_surr or (not os.path.isfile(surr_filename + \".sur\")) or (not os.path.isfile(surr_filename + \".npz\")):\n",
    "    print(\"Warning: Surrogate model files: {0}.npz and {0}.npz could not be found. \".format(surr_filename))\n",
    "    # 4 samples for each dimension: pre-grid size = 16\n",
    "#     exp.surrogate.gen_grid(gridnum=4)\n",
    "    exp.surrogate.gen_grid(gridnum=3)\n",
    "    exp.surrogate.pre_train(exp.surr_pre_it, 0.03, 0.9999, 500, store=True)\n",
    "# Load the surrogate\n",
    "exp.surrogate.surrogate_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run \n",
    "print('')\n",
    "print('--- Temporary TEST: Physics Example - with NOFAS')\n",
    "print('')\n",
    "\n",
    "print('--- Running on device: '+ str(exp.device))\n",
    "print('')\n",
    "\n",
    "# Assign logdensity\n",
    "exp.model_logdensity = lambda x: log_density(x, model, exp.surrogate, trsf)\n",
    "\n",
    "# Run VI\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that the model evaluation has been successfully completed by checking at the newly created **phys** folder in our current directory.<br>\n",
    "> Note that LINFA supports a post processing script to plot all results which includes plots of log loss, parameter estimation, and estimated output data. <br>\n",
    "The according code line is: `python -m linfa.plot_res -n phys -i 25000 -f phys`\n",
    "<br>\n",
    "\n",
    "    \n",
    "> Now, to compare the functionalities of the surrogate model, we observe the plots generated by the LINFA library.\n",
    "<br>\n",
    "Note that the generated plots below are converted to png format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "from IPython.display import IFrame\n",
    "\n",
    "## Phys. without Surrogate\n",
    "# 1-a) output evaluation plots - without surrogate\n",
    "output1_free = convert_from_path('./phys_nofasFree/data_plot_phys_nofasFree_25000_0_1.pdf')\n",
    "for page in output1_free:\n",
    "    page.save('data_plot_phys_nofasFree_25000_0_1.png', 'PNG')\n",
    "    \n",
    "output2_free = convert_from_path('./phys_nofasFree/data_plot_phys_nofasFree_25000_0_2.pdf')\n",
    "for page in output2_free:\n",
    "    page.save('data_plot_phys_nofasFree_25000_0_2.png', 'PNG')\n",
    "    \n",
    "output3_free = convert_from_path('./phys_nofasFree/data_plot_phys_nofasFree_25000_1_2.pdf')\n",
    "for page in output3_free:\n",
    "    page.save('data_plot_phys_nofasFree_25000_1_2.png', 'PNG')\n",
    "    \n",
    "# 1-b) output evaluation plots - with surrogate\n",
    "output1 = convert_from_path('./phys/data_plot_phys_25000_0_1.pdf')\n",
    "for page in output1:\n",
    "    page.save('data_plot_phys_25000_0_1.png', 'PNG')\n",
    "    \n",
    "output2 = convert_from_path('./phys/data_plot_phys_25000_0_2.pdf')\n",
    "for page in output2:\n",
    "    page.save('data_plot_phys_25000_0_2.png', 'PNG')\n",
    "    \n",
    "output3 = convert_from_path('./phys/data_plot_phys_25000_1_2.pdf')\n",
    "for page in output3:\n",
    "    page.save('data_plot_phys_25000_1_2.png', 'PNG')\n",
    "    \n",
    "# 2-a) log-loss plots - without surrogate\n",
    "log_free = convert_from_path('./phys_nofasFree/log_plot.pdf')\n",
    "for page in log_free:\n",
    "    page.save('log_plot_nofasFree.png', 'PNG')\n",
    "\n",
    "# 2-b) log-loss plots - with surrogate\n",
    "log_free = convert_from_path('./phys/log_plot.pdf')\n",
    "for page in log_free:\n",
    "    page.save('log_plot_phys.png', 'PNG')\n",
    "    \n",
    "# 3-a) parameter evaluation plots - without surrogate\n",
    "param1_free = convert_from_path('./phys_nofasFree/params_plot_phys_nofasFree_25000_0_1.pdf')\n",
    "for page in param1_free:\n",
    "    page.save('params_plot_phys_nofasFree_25000_0_1.png', 'PNG')  \n",
    "    \n",
    "param2_free = convert_from_path('./phys_nofasFree/params_plot_phys_nofasFree_25000_0_2.pdf')\n",
    "for page in param2_free:\n",
    "    page.save('params_plot_phys_nofasFree_25000_0_2.png', 'PNG')  \n",
    "    \n",
    "param3_free = convert_from_path('./phys_nofasFree/params_plot_phys_nofasFree_25000_1_2.pdf')\n",
    "for page in param3_free:\n",
    "    page.save('params_plot_phys_nofasFree_25000_1_2.png', 'PNG')  \n",
    "    \n",
    "# 3-b) parameter evaluation plots - with surrogate\n",
    "param1 = convert_from_path('./phys/params_plot_phys_25000_0_1.pdf')\n",
    "for page in param1:\n",
    "    page.save('params_plot_phys_25000_0_1.png', 'PNG')    \n",
    "    \n",
    "param2 = convert_from_path('./phys/params_plot_phys_25000_0_2.pdf')\n",
    "for page in param2:\n",
    "    page.save('params_plot_phys_25000_0_2.png', 'PNG')   \n",
    "    \n",
    "param3 = convert_from_path('./phys/params_plot_phys_25000_1_2.pdf')\n",
    "for page in param3:\n",
    "    page.save('params_plot_phys_25000_1_2.png', 'PNG')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We first take a look to check if the images are well converted to png\n",
    "\n",
    "# import package\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# display png image\n",
    "img1 = Image(filename='output1_free.png')\n",
    "img2 = Image(filename='output2_free.png')\n",
    "img3 = Image(filename='output3_free.png')\n",
    "# display(img1, img2, img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we compare the generated plots of log-loss, output data and parameter estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) *log-loss* plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## log-loss plots\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "# setting row and column variables\n",
    "rows = 1\n",
    "columns = 2\n",
    "\n",
    "# reading images\n",
    "logLoss_phys = cv2.imread('log_plot_phys.png')\n",
    "logLoss_physFree = cv2.imread('log_plot_nofasFree.png')\n",
    "\n",
    "# Adds a subplot at the 1st position\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "\n",
    "# Add subplots corresponding to Phys with Surrogate\n",
    "plt.imshow(logLoss_phys)\n",
    "plt.axis('off')\n",
    "plt.title(\"Phys. with Surrogate\")\n",
    "\n",
    "# Add subplots corresponding to Phys without Surrogate\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "# showing image\n",
    "plt.imshow(logLoss_physFree)\n",
    "plt.axis('off')\n",
    "plt.title(\"Phys. without Surrogate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While both of the log loss plots show convergence to a lower log loss value, notice that the log loss plot of the Phys. model that utilized the Surrogate model had a lower log loss value than the case when the Surrogate was not used.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) *ouput estimation* plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output plots\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "# setting row and column variables\n",
    "rows = 3\n",
    "columns = 2\n",
    "\n",
    "# reading images\n",
    "phys1 = cv2.imread('data_plot_phys_25000_0_1.png')\n",
    "phys2 = cv2.imread('data_plot_phys_25000_0_2.png')\n",
    "phys3 = cv2.imread('data_plot_phys_25000_1_2.png')\n",
    "# print('Image Width is',Image1.shape[1]) #327\n",
    "# print('Image Height is',Image1.shape[0]) #259\n",
    "# Image1 = cv2.resize(Image1, (400,300))\n",
    "\n",
    "physFree1 = cv2.imread('data_plot_phys_nofasFree_25000_0_1.png')\n",
    "physFree2 = cv2.imread('data_plot_phys_nofasFree_25000_0_2.png')\n",
    "physFree3 = cv2.imread('data_plot_phys_nofasFree_25000_1_2.png')\n",
    "\n",
    "# Add subplots corresponding to Phys with Surrogates\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(phys1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Phys. with Surrogate\")\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(phys2)\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 5)\n",
    "plt.imshow(phys3)\n",
    "plt.axis('off')\n",
    "\n",
    "# Add subplots corresponding to Phys without Surrogate\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(physFree1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Phys. with Surrogate\")\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(physFree2)\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 6)\n",
    "plt.imshow(physFree3)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While both of the output plots have meaningful results where the samples (blue dots) are distributed within the estimated region (red cluster), notice that the samples are much more clustered within the estimated area from the Phys. model that utilized the Surrogate model than the case where the Surrogate model was not used.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) *parameter estimation* plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameter estimation plots\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "# setting row and column variables\n",
    "rows = 3\n",
    "columns = 2\n",
    "\n",
    "# reading images\n",
    "phys1 = cv2.imread('params_plot_phys_25000_0_1.png')\n",
    "phys2 = cv2.imread('params_plot_phys_25000_0_2.png')\n",
    "phys3 = cv2.imread('params_plot_phys_25000_1_2.png')\n",
    "\n",
    "physFree1 = cv2.imread('params_plot_phys_nofasFree_25000_0_1.png')\n",
    "physFree2 = cv2.imread('params_plot_phys_nofasFree_25000_0_2.png')\n",
    "physFree3 = cv2.imread('params_plot_phys_nofasFree_25000_1_2.png')\n",
    "\n",
    "# Add subplots corresponding to Phys with Surrogates\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(phys1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Phys. with Surrogate\")\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(phys2)\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 5)\n",
    "plt.imshow(phys3)\n",
    "plt.axis('off')\n",
    "\n",
    "# Add subplots corresponding to Phys without Surrogate\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(physFree1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Phys. without Surrogate\")\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(physFree2)\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 6)\n",
    "plt.imshow(physFree3)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Recall our input values (parameters) were [1,5,60]. Notice that both cases successfully returns parameter estimations that are fairly accurate. Specifically, we observe that when the Surrogate model is used, the accuracy of the parameter estimation increases.\n",
    "<br>\n",
    "\n",
    "> Based on the generated plots, we've observed the physical benefits of the Surrogate model and the functionality of the Phys. model estimation utilizing LINFA. \n",
    "> Moreover, LINFA supports various model types. For more information, please refer to our paper **[need to put our paper url!!!]** *Appendix B. Detailed numerical benchmarks* where examples utilizing the LINFA library is introduced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
