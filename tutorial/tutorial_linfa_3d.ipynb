{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINFA Tutorial\n",
    "This LINFA tutorial will guide you through using the most common functionalities of LINFA with a hands-on examples.\n",
    "<br>\n",
    "\n",
    "* **What is LINFA?**\n",
    "<br> \n",
    "    LINFA is a library for variational inference with normalizing flow and adaptive annealing. LINFA accommodates computationally expensive models and difficult-to-sample posterior distributions with dependent parameters.\n",
    "    \n",
    "* **Why should I use LINFA?**\n",
    "<br>\n",
    "    Designed as a general inference engine, LINFA allows the user to define custom input transformations, computational models, surrogates, and likelihood functions which will be discussed throughout the tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial outline\n",
    "\n",
    "In this tutorial we will:\n",
    "\n",
    "1. Analyze and implement a physics-based model for a ballistic application.\n",
    "\n",
    "2. Generate a set of synthetic observations.\n",
    "\n",
    "3. Compute the model gradients using PyTorch and verify their correctness through a finite difference approximation.\n",
    "\n",
    "4. Perform an inference tasks with LINFA:\n",
    "\n",
    "    * Case 1: Variational inference with the original model.\n",
    "\n",
    "    * Case 2: Variational inference with a lightweight neural network surrogate.\n",
    "\n",
    "After going through this tutorial, you will be able to integrate you favorite physics-based model with LINFA, to perform inference tasks.\n",
    "<br>\n",
    "\n",
    "In addition, we emphasize two special features available through LINFA:\n",
    "\n",
    "* Adaptively trained surrogate models (NoFAS module).\n",
    "\n",
    "* Adaptive annealing schedulers (AdaAnn module).\n",
    "\n",
    "We encourage the user to take advantage of such features, especially when using physics-based models with computationally expensive evaluations. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "#### Background theory and examples for LINFA\n",
    "\n",
    "* Y. Wang, E.R. Cobian, J. Lee, F. Liu, J.D. Hauenstein, D.E. Schiavazzi, [LINFA: a Python library for variational inference with normalizing flow and annealing](https://arxiv.org/abs/2307.04675)\n",
    "\n",
    "* Y. Wang, F. Liu and D.E. Schiavazzi, [Variational Inference with NoFAS: Normalizing Flow with Adaptive Surrogate for Computationally Expensive Models](https://www.sciencedirect.com/science/article/abs/pii/S0021999122005162)\n",
    "\n",
    "* E.R. Cobian, J.D. Hauenstein, F. Liu and D.E. Schiavazzi, [AdaAnn: Adaptive Annealing Scheduler for Probability Density Approximation](https://www.dl.begellhouse.com/journals/52034eb04b657aea,796f39cb1acf1296,6f85fe1149ff41d9.html?sgstd=1)\n",
    "\n",
    "#### More about LINFA library: \n",
    "\n",
    "* LINFA library [documentation](https://linfa-vi.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "* LINFA GitHub [repository](https://github.com/desResLab/LINFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries ##\n",
    "import os\n",
    "import linfa\n",
    "from linfa.run_experiment import experiment\n",
    "from linfa.transform import Transformation\n",
    "from linfa.nofas import Surrogate\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem definition\n",
    "* Our physics-based model **phys** consists of a simple ballistic model. It computes the outputs: \n",
    "    * maximum height (m) $x_{1}$,\n",
    "    * final landing location (m) of the object $x_{2}$,\n",
    "    * total flight time (s)  $x_{2}$,\n",
    "    \n",
    "    from the inputs:\n",
    "    * starting position (m) $z_{1}$,\n",
    "    * initial velocity (m/s)  $z_{2}$,\n",
    "    * angle (degrees) $z_{3}$.\n",
    "<br>\n",
    "\n",
    "The model is described by the following equations\n",
    "$$\n",
    "x_{1} = \\frac{z_{2}^{2}\\,\\sin^{2}(z_{3})}{2\\,g},\\,\\,\n",
    "x_{2} = z_{1} + \\frac{z_{2}^{2}\\,\\sin(2\\,z_{3})}{g},\\,\\,\n",
    "x_{3} = \\frac{2\\,z_{2}\\,\\sin(z_{3})}{g}.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model identifiability\n",
    "\n",
    "By considering fixed values for the outputs $(x_{1},x_{2},x_{3}) = (\\widetilde{x}_{1},\\widetilde{x}_{2},\\widetilde{x}_{3})$, we can perform some algebraic manipulation to investigate structural identifiability. For example, if we derive $z_{2}$ from the equation for $x_{3}$ and we plug it back in the equation for $x_{1}$, we get the equation\n",
    "$$\n",
    "g\\,\\frac{\\widetilde{x}_{3}^{2}}{8} = \\widetilde{x}_{1}^{2}.\n",
    "$$\n",
    "\n",
    "The maximum height and time of flight are, as expected, related by a deterministic condition and therefore only one of these provide an independent information for the solution of the inverse problem. \n",
    "\n",
    "Due to this dependence, the number of observables is reduced to only two, from three inputs. This results in a non-identifiable inference task. In other words, there is an infinite number of input combinations $(z_{1},z_{2},z_{3})$ corresponding to the outputs $(\\widetilde{x}_{1},\\widetilde{x}_{2},\\widetilde{x}_{3})$. \n",
    "\n",
    "A graphical explanation for this lack of identifiability can be is shown in the the plot below\n",
    "\n",
    "<img src=\"imgs/trajectories.png\" width=\"800px\" aligned=\"center\"><br>\n",
    "**Figure:** Examples of trajectories resulting in the same landing distance and maximum height (or time of flight).\n",
    "\n",
    "This picture shows how the final target location at $x_{2}$ can be reached by multiple initial positions, velocities and angles. The lack of identifiability also translates in the existence of a one-dimensional manifold of inputs that correspond to the same outputs. This manifold can be determined from the following expressions in the form $z_1(z_{3})$ and $z_2(z_{3})$ \n",
    "$$\n",
    "z_{1} = \\widetilde{x}_{2} - \\frac{g\\cdot \\widetilde{x}_{3}^{2}}{2}\\cdot \\left[\\frac{\\cos(z_{3})}{\\sin(z_{3})}\\right],\\,\\,\n",
    "z_{2} = \\frac{g\\cdot \\widetilde{x}_{3}}{2\\,\\sin(z_{3})}.\n",
    "$$\n",
    "These two curves are plotted below.\n",
    "\n",
    "<img src=\"imgs/non_ident.png\" width=\"800px\" aligned=\"center\"><br>\n",
    "**Figure:** Two-dimensional projections of one-dimensional manifold where all parameters correspond to the same outputs. When performing inference we therefore expect the posterior distribution to be concentrated around such curves. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation as a Python class\n",
    "\n",
    "* We first create a new **Phys** model class, having three member functions:\n",
    "\n",
    "    * `__init__` - A constructor.\n",
    "\n",
    "    * `genDataFile` - A member function to create synthetic observations.\n",
    "\n",
    "    * `solve_t` - A function to perform forward model evaluations.\n",
    "\n",
    "*Please refer to the comments below for additional implementation details.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Implementation of the traditional trajectory motion physics problem ####\n",
    "class Phys:\n",
    "    \n",
    "    ### Define constructor function for Phys class ###\n",
    "    def __init__(self):\n",
    "        ## Define input parameters (True value)  \n",
    "        # input[] = [starting_position, initial_velocity, angle] = [1(m), 5(m/s), 60(degs)]\n",
    "        self.defParam = torch.Tensor([[1.0, 5.0, 60.0]])\n",
    "\n",
    "        self.gConst = 9.81   # gravitational constant\n",
    "        self.stdRatio = 0.05 # standard deviation ratio\n",
    "        self.data = None     # data set of model sample\n",
    "\n",
    "    ### Define data file generator function ###\n",
    "    # dataSize (int): size of sample (data)\n",
    "    # dataFileName (String): name of the sample data file\n",
    "    # store (Boolean): True if user wish to store the generated data file; False otherwise.\n",
    "    def genDataFile(self, dataSize = 50, dataFileName=\"data_phys_3d.txt\", store=True):\n",
    "        def_out = self.solve_t(self.defParam)[0]\n",
    "        self.data = def_out + self.stdRatio * torch.abs(def_out) * torch.normal(0, 1, size=(dataSize, 3))\n",
    "        self.data = self.data.t().detach().numpy()\n",
    "        if store: np.savetxt(dataFileName, self.data)\n",
    "        return self.data\n",
    "\n",
    "    ### Define data file generator function ###\n",
    "    # params (Tensor): input parameters storing starting position, initial velocity, and angle in corresponding order.\n",
    "    def solve_t(self, params):\n",
    "        z1, z2, z3 = torch.chunk(params, chunks=3, dim=1) # input parameters\n",
    "        z3 = z3 * (np.pi / 180)                           # convert unit from degree to radians\n",
    "        \n",
    "        ## Output value calculation\n",
    "        # ouput[] = [maximum_height, final_location, total_time]\n",
    "        x = torch.cat(( (z2 * z2 * torch.sin(z3) * torch.sin(z3)) / (2.0 * self.gConst),  # x1: maxHeight\n",
    "            z1 + ((z2 * z2 * torch.sin(2.0 * z3)) / self.gConst),                         # x2: finalLocation \n",
    "            (2.0 * z2 * torch.sin(z3)) / self.gConst), 1)                                 # x3: totalTime\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04677002",
   "metadata": {},
   "source": [
    "### Generation of synthetic data\n",
    "\n",
    "The *genDataFile* member function is designed to generate multiple synthetic outputs by adding Gaussian noise around the output corresponding to a *default parameter set* \n",
    "$$\\boldsymbol{z}^{*} = (1.0, 5.0, 60.0)$$\n",
    "where the initial angle of the trajectory is measured in degrees. The following code generates 50 synthetic observations and stores them in the *data_phys.txt* file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate phys sample file ##\n",
    "# Define model\n",
    "model = Phys()\n",
    "# Generate Data\n",
    "physData = model.genDataFile()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model set up, we go on to our second step and check the computation of its gradient."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Gradient Calculation\n",
    "\n",
    "* Prior to applying NoFAS to our **Phys** model, we check if the model gradient (Jacobian actually since it has multiple outputs) is correctly computed by PyTorch. \n",
    "\n",
    "* Specifically, when the surrogate is not enabled, gradient calculation is completed straight through the model, so we want to ensure that this is correct before running an inference task.\n",
    "\n",
    "* Here we compute each gradient using (1) Pytorch and (2) a forward Euler finite difference approximation, and compare the results provided by these two approaches."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Computing gradients through PyTorch\n",
    "\n",
    " We define a new class to compute gradients. The class is construced by specifying a model and a transformation and provides member functions to compute the derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Implementation of gradient calculation using PyTorch - version 2 #### \n",
    "class PytorchGrad: \n",
    "    \n",
    "    ### Define constructor function for PytorchGrad2 class ###\n",
    "    def __init__(self, model, transform):\n",
    "        # Define input parameters and enable gradient calculation\n",
    "        self.z = torch.Tensor([[1.0, 5.0, 60.0]])\n",
    "        self.z.requires_grad = True\n",
    "        \n",
    "        self.in_vals = transform.forward(self.z)\n",
    "\n",
    "        self.out_val = model.solve_t(self.in_vals)\n",
    "        self.out1, self.out2, self.out3 = torch.chunk(self.out_val, chunks=3, dim=1)\n",
    "\n",
    "    # Compute gradients using backward function for y\n",
    "    def back_x1(self): \n",
    "        self.out1.backward()\n",
    "        d1 = self.z.grad\n",
    "        a, b, c = torch.chunk(d1, chunks=3, dim=1)\n",
    "        return [a.item(), b.item(), c.item()]\n",
    "    \n",
    "    def back_x2(self): \n",
    "        self.out2.backward()\n",
    "        d2 = self.z.grad\n",
    "        a, b, c = torch.chunk(d2, chunks=3, dim=1)\n",
    "        return [a.item(), b.item(), c.item()]\n",
    "    \n",
    "    def back_x3(self): \n",
    "        self.out3.backward()\n",
    "        d3 = self.z.grad\n",
    "        a, b, c = torch.chunk(d3, chunks=3, dim=1)\n",
    "        return [a.item(), b.item(), c.item()]\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22f27744",
   "metadata": {},
   "source": [
    "We then use the class with the **Phys** model and an *identity* transformation as shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dz1</th>\n",
       "      <th>dz2</th>\n",
       "      <th>dz3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dx1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382263</td>\n",
       "      <td>0.019260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dx2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882799</td>\n",
       "      <td>-0.044478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dx3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.008896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dz1       dz2       dz3\n",
       "dx1  0.0  0.382263  0.019260\n",
       "dx2  1.0  0.882799 -0.044478\n",
       "dx3  0.0  0.176560  0.008896"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Phys model\n",
    "model = Phys()\n",
    "\n",
    "# Set transformation information and define transforamtion\n",
    "trsf_info = [['identity',0.0,0.0,0.0,0.0],\n",
    "             ['identity',0,0.0,0.0,0.0],\n",
    "             ['identity',0,0.0,0.0,0.0]]\n",
    "        \n",
    "transform = Transformation(trsf_info)\n",
    "\n",
    "# List to store dx/dz values\n",
    "dx_dz_pytorch = []\n",
    "\n",
    "# Define PytorchGrad object and calculate gradient\n",
    "pyGrad = PytorchGrad(model, transform)\n",
    "dx_dz_pytorch.append(pyGrad.back_x1())\n",
    "\n",
    "pyGrad = PytorchGrad(model, transform)\n",
    "dx_dz_pytorch.append(pyGrad.back_x2())\n",
    "\n",
    "pyGrad = PytorchGrad(model, transform)\n",
    "dx_dz_pytorch.append(pyGrad.back_x3())\n",
    "\n",
    "# convert to pandas DataFrame for readability\n",
    "jacob_mat_2 = pd.DataFrame(dx_dz_pytorch, columns=['dz1', 'dz2', 'dz3'])\n",
    "jacob_mat_2.index = ['dx1', 'dx2', 'dx3']\n",
    "jacob_mat_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximating gradients with finite differences\n",
    "\n",
    "We now apply the forward Euler approximation of the gradient to verify the results above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that manually calculates a derivative ###\n",
    "def getGrad(f_eps, f, eps):\n",
    "    return (f_eps - f) / (eps)\n",
    "\n",
    "### Function that returns a list of gradients ###\n",
    "def gradList(f_eps1, f_eps2, f_eps3, f, eps): \n",
    "    return [getGrad(f_eps1, f, eps).item(), getGrad(f_eps2, f, eps).item(), getGrad(f_eps3, f, eps).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dz1</th>\n",
       "      <th>dz2</th>\n",
       "      <th>dz3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dx1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420489</td>\n",
       "      <td>0.019062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dx2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971078</td>\n",
       "      <td>-0.045814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dx3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.008761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dz1       dz2       dz3\n",
       "dx1  0.0  0.420489  0.019062\n",
       "dx2  1.0  0.971078 -0.045814\n",
       "dx3  0.0  0.176560  0.008761"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List to store dx/dz values\n",
    "dx_dz = []\n",
    "dx1_dz = []\n",
    "dx2_dz = []\n",
    "dx3_dz = []\n",
    "\n",
    "# Set up parameters\n",
    "eps = 1.0\n",
    "z = torch.Tensor([[1.0, 5.0, 60.0]])\n",
    "z_eps1 = torch.Tensor([[1.0 + eps, 5.0, 60.0]])\n",
    "z_eps2 = torch.Tensor([[1.0, 5.0 + eps, 60.0]])\n",
    "z_eps3 = torch.Tensor([[1.0, 5.0, 60.0 + eps]])\n",
    "\n",
    "x1_eps1 = model.solve_t(z_eps1)[0,0]\n",
    "x1_eps2 = model.solve_t(z_eps2)[0,0]\n",
    "x1_eps3 = model.solve_t(z_eps3)[0,0]\n",
    "x1_eps = model.solve_t(z)[0,0]\n",
    "\n",
    "dx1_dz = gradList(x1_eps1, x1_eps2, x1_eps3, x1_eps, eps)\n",
    "dx_dz.append(dx1_dz)\n",
    "\n",
    "x2_eps1 = model.solve_t(z_eps1)[0,1]\n",
    "x2_eps2 = model.solve_t(z_eps2)[0,1]\n",
    "x2_eps3 = model.solve_t(z_eps3)[0,1]\n",
    "x2_eps = model.solve_t(z)[0,1]\n",
    "\n",
    "dx2_dz = gradList(x2_eps1, x2_eps2, x2_eps3, x2_eps, eps)\n",
    "dx_dz.append(dx2_dz)\n",
    "\n",
    "x3_eps1 = model.solve_t(z_eps1)[0,2]\n",
    "x3_eps2 = model.solve_t(z_eps2)[0,2]\n",
    "x3_eps3 = model.solve_t(z_eps3)[0,2]\n",
    "x3_eps = model.solve_t(z)[0,2]\n",
    "\n",
    "dx3_dz = gradList(x3_eps1, x3_eps2, x3_eps3, x3_eps, eps)\n",
    "dx_dz.append(dx3_dz)\n",
    "\n",
    "# convert to pandas DataFrame for readability\n",
    "jacob_mat_3 = pd.DataFrame(dx_dz, columns=['dz1', 'dz2', 'dz3'])\n",
    "jacob_mat_3.index = ['dx1', 'dx2', 'dx3']\n",
    "jacob_mat_3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the convergence of the finite difference approximation to the gradient\n",
    "\n",
    "- *Note*: if you'd like you can adjust the script below to check convergence for other components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Focus: dx2_dz3\n",
    "\n",
    "initial_eps = 15        # Initial change of value (eps)\n",
    "k = 150                 # Number of iterations\n",
    "dx2_dz3_list = []       # List to store results\n",
    "pytorch_grad2 = -0.0445 # Pytorch gradient value\n",
    "\n",
    "# Calculate for dx2_dz3 as eps decreases\n",
    "for t in range(1, k):\n",
    "    update_eps = initial_eps*(1/t)                             # updated eps value\n",
    "    z_eps3 = torch.Tensor([[1.0, 5.0, 60.0 + update_eps]])     # update z_eps3\n",
    "    x2_eps3 = model.solve_t(z_eps3)[0,1]                       # update x2_eps3\n",
    "    dx2_dz3_list.append(getGrad(x2_eps3, x2_eps, update_eps))  # store result to dx2_dz3_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABC0klEQVR4nO3de1xUdfrA8Q8X8Z4zoMIKCGjWWmuGiGlqaualzUu3LcsCL2vZbtta7Qpppa7+Su1mv36lG7WG5T01cdsUTLC8j3JPcbipiAKpYJhu3p7fH+jJcQBRmRnU5/16Pa/hnPme73nOAefxnPOdc9wAQSmllHICd1cnoJRS6sahRUcppZTTaNFRSinlNFp0lFJKOY0WHaWUUk6jRUcppZTTaNFRSinlNFp01A0nPz+fvn37AvDKK68QExPj4owgMjKS77//vtb6e/DBB9m3bx/l5eXceeedtdbveZMmTeLzzz+v9X6rEhQUhIjg4eHhtHUqx9Cio+qUxx9/nC1btnDs2DGKi4vZsmULzz33nMPW9+abbzJmzJir7qcmH4qTJk3i5MmTlJeXU1paysaNG+natetlrysxMZHRo0dX2+btt9/m+eefp2nTpqSmpl72OmpLixYtWLBgAYWFhZSVlbFhwwa6dOnisPU9/vjjZGVlUVZWRnFxMZ999hlNmzZ12PrU5dOio+qMl156iffff5+33noLPz8/fH19GTt2LN27d8fLy6vSZdzdr60/4cWLF9O0aVNatGjBhg0bWL58uUPWExQUxA8//HBFy9bmPm3SpAkWi4WwsDC8vb2JjY3l66+/pnHjxrW2jgtt3LiR7t27YzKZaNOmDZ6enkybNs0h61JXTjQ0XB033XSTHDt2TB5++OFq282dO1c++ugj+frrr+XYsWPSt29f+f3vfy/Jycly9OhR2bdvn0yaNMlmmaeeekr27Nkjhw4dkgkTJkh+fr707dtXAJk0aZJ8/vnnRtu77rpLNm7cKKWlpZKamiq9evUy3ktMTJR//OMfsmHDBvnpp59kzZo14uPjI4Ds3btXRETKy8ulvLxcunbtapf7xeu67bbbRETEx8dHIiMj5fvvvzfe69atm2zbtk3Kyspk27Zt0q1bNwFk2rRpcvr0aTlx4oSUl5fLBx98YLMOLy8vKS8vFxGRY8eOSU5OjgDy29/+VhITE6W0tFQyMzNl8ODB1e7Ti3MPDg6WpKQk+emnnyQ+Pl4++OADY1see+wxycvLk6ZNmwogAwcOlIMHD0rz5s0r/R0ePXpUOnXqVO3v2d3dXd566y358ccfJTc3V/70pz+JiIiHh4d07drV2M/l5eVy4sQJyc/Pt+ujcePGEhsbK19//bXL/741bMLlCWhoyIABA+TUqVPi4eFRbbu5c+dKWVmZ3H333eLm5ib169eXXr16ye9+9ztxc3OTDh06SFFRkQwdOlQAad++vZSXl0vPnj3Fy8tL3nnnHTl16lSlRadVq1Zy6NAhuf/++8XNzU3uu+8+OXTokPHhmZiYKDk5OdKuXTtp0KCBJCYmyptvvimABAUFGR+KVeV+4bq8vLxk5syZsnfvXgFsio7ZbJYjR47IU089JR4eHjJs2DA5cuSIeHt7G3mMHj262v0kItK2bVsBxNPTU7Kzs+WVV16RevXqSZ8+feSnn36SW265pcp9enF/mzZtknfeeUe8vLykZ8+e8tNPP9kU0C+++ELmzp0r3t7eUlhYKA888ECleXXs2FFOnDghN910U7X5P/vss7Jr1y4JCAgQs9ks69atq3T/enp6SlJSkrzxxhvGvO7du0tZWZlRePv16+fyv28Nm3B5AhoaMnz4cDl48KDNvPNHHMePH5eePXsKVHxAxsbGVtvXe++9J++++64A8tprr8nChQuN9xo1aiS//PJLpUVn/PjxMm/ePJu+Vq9eLREREQIVH/YTJ0403nvuuefkm2++Eah50fnll1+ktLRUiouL5dtvvzX+x39h0Xnqqadk69atNstu2rRJIiMjjTwup+j06NFDDh48KG5ubsb7CxYsMI4IL7VPAwMD5dSpU9KoUSNj3vz5822KTrNmzWTv3r2Snp4uc+bMqbSfpk2bSnp6ukRHR1/y7+Hbb7+VZ5991pju169fpfv3o48+klWrVtls2/lo1aqVTJo0Sdq1a+fyv2+NX+PaOiGurluHDx+mefPmNhfiu3fvjtls5vDhwzbXGQoKCmyW7dKlC+vWraOkpISysjLGjh1L8+bNAWjVqpVN++PHj3P48OFKcwgKCuIPf/gDpaWlRvTo0YPf/OY3RpuioiKbvpo0aXJZ27lkyRLMZjO+vr707duX5ORkuzatWrVi7969NvP27t2Lv7//Za3rwv4KCgoQkSr7u3ifXrx8aWkpx48ft1n+QkePHmXp0qV06NCBd955x66PBg0asGrVKrZs2cL06dNrnHNV6wN45pln6N27N08++aTNtp134MABVq9ezaJFiy65PuU8WnRUnbB582Z++eUXhg4desm2F3/ALFiwgLi4OAIDAzGZTMyZMwc3NzcADh48SGBgoNG2YcOG+Pj4VNpvQUEBn3/+OWaz2YgmTZowY8aMy87pahw4cICgoCCbea1bt6awsPCK1nXgwAECAwONfXJxf5fq8+DBg5jNZho1amSz/IU6duzIqFGjWLBgAf/7v/9r856XlxdfffUV+/fv59lnn61Rzhf/3i5eX48ePZg6dSpDhw6lvLy8yn48PT1p27ZtjdapnEOLjqoTjh49ypQpU/joo4945JFHaNKkCW5ubnTs2PGSI52aNm3KkSNH+OWXXwgPD+fJJ5803vvyyy8ZNGgQ3bt3p169evzjH/+ocnTWF198weDBg+nfvz/u7u7Ur1+fXr161egI48cff+TMmTO0adPm8ja8Ev/5z3+45ZZbeOKJJ/Dw8OCxxx7jtttu49///jcAxcXFl7WerVu3cvz4ccaPH4+npye9evVi8ODBNT4C2LdvH9u3b2fKlCnUq1eP7t27M3jwYOP9+vXr88UXXzBhwgRGjhyJv7+/Mczd09OTL7/8khMnThAZGVnjgrlkyRJeeOEF/P39MZlMREdHG+8FBASwZMkSIiIiyM7OtlnuySefNIpV69at+Z//+R++/fbbGq1TOYcWHVVnvPXWW7z00kuMHz+e4uJiiouL+ec//0lUVBSbNm2qcrk//elP/OMf/+Cnn37i9ddfZ8mSJcZ7O3fu5M9//jMLFizg4MGDlJaWsn///kr72b9/P0OHDmXChAn8+OOPFBQU8Pe//71GQ4hPnDjB//zP/7Bx40ZKS0u56667Ln8HnHPkyBEGDRrEyy+/zOHDhxk/fjyDBg0yTgu+//77PProoxw5coT333//kv2dOnWKwYMHc//993Po0CE++ugjIiIi2L17d41zevLJJ7nrrrs4cuQIkyZNYt68ecZ7b775JgUFBcyZM4eTJ0/y1FNPMW3aNG6++Wbuvvtuo5CXlZVRXl5OeXk5PXr0qHZ9MTExrFmzhrS0NJKTk22Glvft2xdfX1++/PJLo7/MzEwAbrvtNjZt2sSxY8fYuHEju3fvrpXvYana40bFxR2llFLK4fRIRymllNNo0VFKucTs2bON02MXxuzZs12dmnIgPb2mlFLKaTxdnUBdVlJSUun3A5RSSlUtKCiIli1bVvqeFp1q7N27l/DwcFenoZRS1xSLxVLle3pNRymllNNo0VFKKeU0WnSUUko5jRYdpZRSTqNFRymllNNo0VFKKeU0OmS6WrcCia5OQimlrhtadJRSNyS3a+T1cn+ureV+AQ5S+7ToVGs30MfVSShVJc9zUe9ceF70WpOfK5vncVF4VjKvuric9lfSt/tVhKqZzcDdV7x01V8OdVnRMZvNLF68mODgYPbs2cNjjz1GWVmZXbuIiAheffVVAKZNm2bzHA+AlStX0qZNGzp06ADApEmTGDNmDD/++CMAEyZM4JtvvgEgOjqa0aNHc+bMGV544QXi4+MduIXqelEPaAg0Ovd6YTQA6gNe514v/Pni15rOO/9ak+LgSqeBM5VEVfOrivPtTwH/rWHbsxe8Xo8hF/0sF80XB77naC4rOtHR0Xz77bfMmDGDqKgooqOjbZ4OCBWFadKkSXTu3BkRYceOHcTFxRnF6aGHHuLYsWN2fb/33nt2z2lv3749w4YN4/bbb6dVq1asXbuWW265hbNnnbGblSO5AU3ORdMavlZWRKqa9qiFHE9Scbri/OsvVcw7fsG8U+fi9GX8XFttL1VI9C7B6kq5rOgMHTqU3r17AxAbG0tSUpJd0RkwYAAJCQmUlpYCkJCQwMCBA1m0aBGNGzfmpZde4plnnrF5UmR161u0aBEnT55kz5495OTk0KVLF7Zs2VLr26YuX1PAGzBXEqYq5t90brnqH2Zt6zhw7NzriXNx/FwcvmjeiUri4vn/peoicuGrUqqCy4qOr68vRUVFABQVFeHr62vXxt/fn4KCAmN6//79xvPqp06dyjvvvMPx48ftlnv++eeJiIhg+/btvPzyy5SVleHv729TYC7sSzmGGQgAfM9Fy3NR2c8NqunnNFAGlF4Qe4CjQPm5OFbJzxfPO4ZzTh8oparm0KKTkJCAn5+f3fyJEyfazROp+QF7x44dadu2LS+99BJBQUE2782ePZupU6ciIkZhGj16dI37HjNmDM888wwAzZs3r/FyNxoPIAhoAwQCrc+9XvhzZUcgJ4ESoPjc684Lfj6MfXEppaJYKKWuDw4tOv369avyveLiYvz8/CgqKsLPz4+SkhK7NoWFhcYpOICAgACSkpLo1q0bnTt3Jj8/H09PT1q2bEliYiJ9+vSx6ScmJoZ///vfRl+BgYE2fRUWFtqtMyYmhpiYGKD623PfKJoBdwC3Ae2AW869tqHigveFDgL7gEzgG6DgXBRRUVRKqCgqSqkbm7giZs6cKVFRUQJIVFSUzJgxw66N2WyWvLw8MZlMYjKZJC8vT8xms02boKAgycjIMKb9/PyMn8eNGycLFy4UQG677TZJTU0VLy8vCQ4OltzcXHF3d682R4vF4pJ946oIAXkE5B8gK0H2gMgF8TNIGsiXIG+CjAS5ByQYpF4dyF9DQ6NuxCU+O12TlLe3t6xdu1asVqskJCQYxSQsLExiYmKMdiNHjpTs7GzJzs6WESNG2PVzcdGZN2+epKenS1pamqxcudKmCE2YMEFycnIkKytLBg4ceLU77poOD5CuIH8DWQ5SxK/F5RRIJsh8kPEgA0ECQNzqQN4aGhp1P6r77HQ794OqhMViua6eHBoEDAD6A32pGBUGkA1sOhfbgR+oGHWllFJXorrPTr0jwXUuCPgD8Bhw/k9gH7AUSACSgB9dkplS6kakRec6VB8YBowFup6btw34OxAHWF2Ul1JKadG5jvgDzwHPAC2oOE0WBSyh4nstSinlalp0rgOBwGvASCpuCRMHfIA+lEEpVfdo0bmGNQZeBV48N/0R8B56VKOUqru06Fyjfg/MoeIoJ5aKI52CapdQSinX08dLXGMaUVFsvqbiFjF3AyPQgqOUujbokc41JAhYCXQAZgCvo3cwVkpdW7ToXCO6UjFAoB5wP6CPn1NKXYv09No1oCcVX+QsA7qgBUcpde3SI506ricVd2zeB9xLxR2blVLqWqVFpw67GfiKioLTm4pHAyil1LVMT6/VUSbg31Q8j/4BtOAopa4PeqRTR30GhFBxN+h816ailFK1RotOHfQUMBR4Gdjg4lyUUqo26em1OuY3wP8CG4FZrk1FKaVqnRadOmYW0ICKm3eedW0qSilV67To1CFhVDxsbSYVT/NUSqnrjRadOmQacBh4x9WJKKWUg+hAgjqiJzAQ+BtQ7uJclFLKUVxypGM2m4mPj8dqtRIfH4/JZKq0XUREBFarFavVSkREhN37K1euJCMjw5hetGgRKSkppKSkkJ+fT0pKCgBBQUEcP37ceG/27NkO2a6r8TpwAPjQ1YkopZSDibNjxowZEhUVJYBERUXJ9OnT7dqYzWbJzc0Vs9ksJpNJcnNzxWQyGe8/9NBDMn/+fMnIyKh0HW+//ba89tprAkhQUFCV7aoLi8XilP3RFkRAJrjgd6GhoaFR23GJz07nJ5SVlSV+fn4CiJ+fn2RlZdm1GTZsmMyZM8eYnjNnjgwbNkwAady4sXz//ffSvn37KovJvn375Oabbxao+0XnDZBTIL+pA38sGhoaGlcb1X12uuT0mq+vL0VFFbeuLCoqwtfX166Nv78/BQW/Ppps//79+Pv7AzB16lTeeecdjh8/Xmn/PXv2pLi4mJycHGNeSEgIycnJJCUl0aNHjypzGzNmDBaLBYvFQvPmza9o+y6HJxXDo78GDjp8bUop5VoOG0iQkJCAn5+f3fyJEyfazRORGvfbsWNH2rZty0svvURQUFClbZ544gkWLlxoTB88eJDWrVtz5MgROnXqxFdffcXtt99Oebn9JfuYmBhiYmIAsFgsNc7rSg0C/IBPHL4mpZRyPYcVnX79+lX5XnFxMX5+fhQVFeHn50dJif3tLAsLC+ndu7cxHRAQQFJSEt26daNz587k5+fj6elJy5YtSUxMpE+fPgB4eHjw8MMPExYWZix78uRJjhw5AkBycjK5ubnccsst7Nixo5a29sqNBgqpeHyBUkrdCJx+vm/mzJk2AwlmzJhh18ZsNkteXp6YTCYxmUySl5cnZrPZpk1l12oGDBggSUlJNvOaN28u7u7uAkhISIjs37/frq/KwtHXdBqCnAB5pw6cg9XQ0NCorahzAwm8vb1l7dq1YrVaJSEhwSgAYWFhEhMTY7QbOXKkZGdnS3Z2towYMcKun8qKzty5c+XZZ5+1mffwww9LZmampKSkyI4dO2TQoEG1seOuOu6nYtTafXXgj0RDQ0OjtqLOFZ1rJRxddP4X5BhI/TqwrRoaGhq1FXVu9JqqMBBIBH5xdSJKKeUkWnRcpC3QDljt6kSUUsqJtOi4yMBzrzpqTSl1I9Gi4yL3U/H4gjxXJ6KUUk6kRcdFugPfujoJpZRyMi06LhACmIBkF+ehlFLOpkXHBe4895riyiSUUsoFtOi4QChwGsh0dSJKKeVkWnRcIBTIAv7r6kSUUsrJtOi4QCh6ak0pdWPSouNkLQB/tOgopW5MWnSc7M5zr1p0lFI3Ii06ThZ67jXVlUkopZSLaNFxslAgHyhzcR5KKeUKWnSc7E70KEcpdePSouNE7kAbKoZLK6XUjUiLjhP5Al7AXlcnopRSLqJFx4kCz70WuDQLpZRyHS06TtT63Os+l2ahlFKu47KiYzabiY+Px2q1Eh8fj8lkqrRdREQEVqsVq9VKRESEMT8xMZGsrCxSUlJISUmhRYsWAHh5ebFo0SKys7PZsmULQUFBxjLR0dFkZ2eTlZVF//79Hbp9ldGio5RSIK6IGTNmSFRUlAASFRUl06dPt2tjNpslNzdXzGazmEwmyc3NFZPJJIAkJiZKWFiY3TLPPfeczJ49WwB5/PHHZdGiRQJI+/btJTU1Vby8vCQ4OFhycnLE3d292hwtFkutbvMskDIX7W8NDQ0NZ0V1n50uO9IZOnQosbGxAMTGxvLggw/atRkwYAAJCQmUlpZSVlZGQkICAwcOtGtXVb9ffvklffv2NeYvWrSIkydPsmfPHnJycujSpUvtbtQlBKLXc5RSNzaXFR1fX1+KiooAKCoqwtfX166Nv78/BQW/fkzv378ff39/Y3ru3LmkpKTw6quvVrrMmTNnOHr0KD4+Ppfs67wxY8ZgsViwWCw0b9786jf0Aq3RU2tKqRubpyM7T0hIwM/Pz27+xIkT7eaJyGX1PXz4cA4cOECTJk1YtmwZTz/9NJ9//vkV53peTEwMMTExAFgslqvu70Ktge212qNSSl1bHFp0+vXrV+V7xcXF+Pn5UVRUhJ+fHyUlJXZtCgsL6d27tzEdEBBAUlISAAcOHADg2LFjLFiwgC5duvD5559TWFhIYGAghYWFeHh40KxZMw4fPmzMv7CvwsLC2tnQGmgAtESPdJRSNzaXnV6Li4sjMjISgMjISFauXGnXZs2aNfTv3x+TyYTJZKJ///6sWbMGDw8PfHx8APD09GTQoEFkZmba9fvoo4+ybt06Y/6wYcPw8vIiODiYdu3asW3bNmdsKqDf0VFKqfNcMrrB29tb1q5dK1arVRISEsRsNgsgYWFhEhMTY7QbOXKkZGdnS3Z2towYMUIAadSokWzfvl3S0tIkMzNTZs2aZYxEq1+/vixZskSys7Nl69atEhISYvQ1YcIEycnJkaysLBk4cOBVjcC43LgXREDuqQMjSzQ0NDQcGZf47HR9gnU1arPojKCi6ATXge3S0NDQcGTUySHTN5rWwFnAeVeRlFKq7tGi4yStgYPAKVcnopRSLqRFx0n0i6FKKaVFx2n0i6FKKaVFx2kCgf2uTkIppVxMi44TeAGNgUOuTkQppVxMi44TNDv3etSlWSillOtp0XGC80WnzJVJKKVUHaBFxwlM5171SEcpdaPTouMEenpNKaUqaNFxAj29ppRSFbToOIHp3Kse6SilbnRadJxAT68ppVSFGhWdRx99tEbzVOVMVNzss9zFeSillKvVqOi88sorNZqnKtcM+ImK+3orpdSNrNrHVQ8cOJDf//73+Pv78/777xvzb7rpJk6fPu3w5K4XzdBBBEopBZcoOgcOHGD79u0MGTKEHTt2GPPLy8t58cUXHZ7c9cKEXs9RSim4RNFJT08nPT2dBQsW6JHNVWiGFh2llIJLFJ3zunTpwuTJkwkKCsLT0xM3NzdEhLZt2zo6v+tCM/QO00opBTUcSPDpp5/y7rvv0qNHD8LDw+ncuTPh4eFXvFKz2Ux8fDxWq5X4+HhMJlOl7SIiIrBarVitViIiIoz5iYmJZGVlkZKSQkpKCi1atADgxRdf5IcffiAtLY21a9fSunVrY5nTp08b7VeuXHnFuV8JE3qko5RS58mlYsuWLZdsczkxY8YMiYqKEkCioqJk+vTpdm3MZrPk5uaK2WwWk8kkubm5YjKZBJDExEQJCwuzW6Z3797SsGFDAWTs2LGyaNEi473y8vLLztNisdTK9h4C+d9a3H8aGhoadTmq++ys0ZFOYmIiM2fOpGvXroSGhhpxpYYOHUpsbCwAsbGxPPjgg3ZtBgwYQEJCAqWlpZSVlZGQkMDAgQOr7TcpKYkTJ04AsGXLFgICAq44x9rUDD3SUUopqOE1nbvuuguAzp07G/NEhL59+17RSn19fSkqKgKgqKgIX19fuzb+/v4UFBQY0/v378ff39+Ynjt3LmfOnGHZsmVMmzbNbvnRo0fzzTffGNMNGjTAYrFw+vRppk+fXuUptjFjxvDMM88A0Lx58yvavgs1pmIna9FRSqkaFp177733sjtOSEjAz8/Pbv7EiRPt5onIZfU9fPhwDhw4QJMmTVi2bBlPP/00n3/+uc37nTt3plevXsa8oKAgDhw4QEhICOvWrSMjI4O8vDy7vmNiYoiJiQHAYrFcVl6VaXbuteyqe1JKqWtfjU6vtWzZkk8++YT//Oc/ALRv355Ro0ZVu0y/fv3o0KGDXcTFxVFcXGwUJD8/P0pKSuyWLywsJDAw0JgOCAigsLAQqPj+EMCxY8dYsGABXbp0Mdr17duXiRMnMmTIEE6ePGnMP79Mfn4+SUlJV3V68HKYzr3qkY5SStWw6Hz22WesWbOGVq1aAWC1Whk3btwVrzQuLo7IyEgAIiMjKz3VtWbNGvr374/JZMJkMtG/f3/WrFmDh4cHPj4+AHh6ejJo0CAyMzMBuPPOO/nnP//JkCFD+PHHH42+TCYTXl5eAPj4+NC9e3d27tx5xflfDj3SUUopW5ccibBt2zYBJDk52ZiXkpJyxSMbvL29Ze3atWK1WiUhIUHMZrMAEhYWJjExMUa7kSNHSnZ2tmRnZ8uIESMEkEaNGsn27dslLS1NMjMzZdasWeLu7i6AJCQkSFFRkaSkpEhKSoqsXLlSAOnWrZukp6dLamqqpKeny6hRo656BEZN434QAelSB0aUaGhoaDgjLvHZeekOEhMTxdvbW3bs2CGA3HXXXZKUlOTyDXPxjqtRDKOi6NxaB7ZHQ0NDwxlR3WdnjQYSvPTSS8TFxdG2bVs2bNhAixYt9NEGNdTs3GuZK5NQSqk6okZFJyUlhV69enHrrbfi5ubG7t279V5sNWQ696oDCZRS6hJFp0+fPiQmJvLQQw/ZzL/lllsAWLFiheMyu040A34B/uvqRJRSqg6otuj06tWLxMREBg8ebPeeiGjRqQETepSjlFLnVVt0Jk+eDHDJ7+SoqjVDi45SSp1XbdG51IPa3nvvvVpN5nrUDB1EoJRS51VbdJo2bQrArbfeSnh4OHFxcQAMHjyYbdu2OT6764AJPdJRSqkLXXLM9fr166VJkybGdJMmTWT9+vUuHwvu6KiN7+lkgCytA9uioaGh4ay46kcb+Pr62tzH7OTJk5XeGVrZM6FHOkopdV6Nvqczb948tm3bZoxWe/DBB43n4ajqNUOLjlJKnVejovPGG2+wevVqevToAcDIkSNJTU11ZF7XBXegKVp0lFLqvBoVHYDk5GQKCgpo0KABAIGBgTYPWVP2Gpx7Pe7SLJRSqu6o0TWdwYMHY7Vayc/PZ/369eTn59s8lVNVrt6515PVtlJKqRtHjYrO1KlT6dq1K1arlTZt2nDfffexZcsWR+d2zfM693rKpVkopVTdUaOic+rUKY4cOYK7uztubm4kJSXRuXNnR+d2zTtfdPRIRymlKtTomk5ZWRmNGzfmu+++Y/78+ZSUlPDzzz87OrdrnhYdpZSyVaMjnaFDh3L8+HFefPFFVq9eTW5ubqU3AVW29JqOUkrZuuSRjru7O//+97+59957OXPmDPPmzXNGXtcFvaajlFK2Lnmkc/bsWc6ePctNN93kjHyuK3p6TSmlbNXo9NqxY8fIyMjgk08+4f333zfiSpnNZuLj47FarcTHx2MymSptFxERgdVqxWq1EhERYcxPTEwkKyuLlJQUUlJSaNGiBQCRkZGUlJQY80ePHn3JvhxJT68ppZStGg0kWL58OcuXLwdARABwc3O74pVGR0fz7bffMmPGDKKiooiOjiY6OtqmjdlsZtKkSXTu3BkRYceOHcTFxVFWVgbA8OHD2bFjh13fixcv5i9/+ctl9eUoenpNKaVsVVt0hgwZQkBAAB999BEAW7dupUWLFogIUVFRV7zSoUOH0rt3bwBiY2NJSkqyKzoDBgwgISGB0tJSABISEhg4cCCLFi267PXVZl+XQ0+vKaWUrWpPr40fP954hg6Al5cXYWFh9O7dm7Fjx17xSn19fSkqKgKgqKio0jtW+/v729xmZ//+/fj7+xvTc+fOJSUlhVdffdVmuUceeYS0tDSWLl1KQEBAjfq60JgxY7BYLFgsFpo3b37F2whadJRS6mLVFh0vLy/2799vTG/YsIHS0lIKCgpo3LhxtR0nJCSQkZFhF0OGDLFre/6UXU0NHz6cO+64g549e9KzZ0+efvppAFatWkVwcDAdO3YkISHhiu6EHRMTQ3h4OOHh4Rw6dOiyl7+QXtNRSilb1RYds9lsM33htZLzF++r0q9fPzp06GAXcXFxFBcX4+fnB4Cfnx8lJSV2yxcWFhIYGGhMBwQEUFhYCMCBAweAigEOCxYsoEuXLgAcOXLEeO7PJ598QlhY2CX7ciS9pqOUUraqLTpbt27lj3/8o938Z5555qoeVx0XF0dkZCRQMeJs5cqVdm3WrFlD//79MZlMmEwm+vfvz5o1a/Dw8MDHxwcAT09PBg0aRGZmJoBRyKDietSuXbuq7cvR9PSaUkrZq/Kxoi1atJCNGzfKunXr5O2335a3335bEhMTZdOmTdKyZcsrfpSpt7e3rF27VqxWqyQkJIjZbBZAwsLCJCYmxmg3cuRIyc7OluzsbBkxYoQA0qhRI9m+fbukpaVJZmamzJo1S9zd3QWQN954QzIzMyU1NVXWrVsnt956a7V9XSqu9nHVkSAC0roOPD5WQ0NDw1lR3Wen27kfqtWnTx9uv/12AH744QcSExMvtch1wWKxEB4efsXLjwE+BloBB2srKaWUquOq++ys0fd0EhMTb5hCU5v09JpSStmq0R0J1JXRoqOUUra06DiQDplWSilbWnQcSIdMK6WULS06DuQFnAHOujoRpZSqI7ToOJAXempNKaUupEXHgeqhp9aUUupCWnQcSI90lFLKlhYdB9Kio5RStrToOJCeXlNKKVtadBxIj3SUUsqWFh0H0qKjlFK2tOg4kBYdpZSypUXHgfSajlJK2dKi40B6pKOUUra06DiQFh2llLKlRceB9PSaUkrZ0qLjQHqko5RStrToOJAWHaWUsuWSomM2m4mPj8dqtRIfH4/JZKq0XUREBFarFavVSkREhDE/MTGRrKwsUlJSSElJoUWLFgC8++67xrzdu3dTWlpqLHP69GnjvZUrVzp0+87ToqOUUvbE2TFjxgyJiooSQKKiomT69Ol2bcxms+Tm5orZbBaTySS5ubliMpkEkMTERAkLC6t2Hc8//7x8+umnxnR5efll52mxWK5qO3NBYl2wfzU0NDRcGdV9drrkSGfo0KHExsYCEBsby4MPPmjXZsCAASQkJFBaWkpZWRkJCQkMHDiwxut44oknWLhwYW2lfEX0SEcppWy5pOj4+vpSVFQEQFFREb6+vnZt/P39KSgoMKb379+Pv7+/MT137lxSUlJ49dVX7ZZt3bo1ISEhrFu3zpjXoEEDLBYLmzdvZujQoVXmNmbMGCwWCxaLhebNm1/R9p2nRUcppWx5OqrjhIQE/Pz87OZPnDjRbp6IXFbfw4cP58CBAzRp0oRly5bx9NNP8/nnnxvvDxs2jC+//JKzZ399UHRQUBAHDhwwilFGRgZ5eXl2fcfExBATEwOAxWK5rLwupkOmlVLKlsOKTr9+/ap8r7i4GD8/P4qKivDz86OkpMSuTWFhIb179zamAwICSEpKAuDAgQMAHDt2jAULFtClSxe7ovPnP//Zpr/zy+Tn55OUlERoaGilRac26ZGOUkrZcsnptbi4OCIjIwGIjIysdDTZmjVr6N+/PyaTCZPJRP/+/VmzZg0eHh74+PgA4OnpyaBBg8jMzDSWu/XWWzGbzWzevNmYZzKZ8PLyAsDHx4fu3buzc+dOR24ioEVHKaUq4/SRDd7e3rJ27VqxWq2SkJAgZrNZAAkLC5OYmBij3ciRIyU7O1uys7NlxIgRAkijRo1k+/btkpaWJpmZmTJr1ixxd3c3lpk0aZK8+eabNuvr1q2bpKenS2pqqqSnp8uoUaOuegRGTUJAXq8DI0k0NDQ0nBmX+Ox0fYJ1Na6m6NSjoui8Uge2Q0NDQ8OZUeeGTN8IvM696uk1pZT6lRYdB9Gio5RS9rToOEi9c686ZFoppX6lRcdB9EhHKaXsadFxEC06SillT4uOg2jRUUope1p0HESv6SillD0tOg6iRzpKKWVPi46DaNFRSil7WnQcRE+vKaWUPS06DqJHOkopZU+LjoNo0VFKKXtadBzkfNHR02tKKfUrLToOcv6ajh7pKKXUr7ToOIieXlNKKXtadBxEi45SStnTouMgek1HKaXsadFxEL2mo5RS9rToOIieXlNKKXuerlqx2Wxm8eLFBAcHs2fPHh577DHKysrs2kVERPDqq68CMG3aNObNmwdAvXr1+L//+z969+7N2bNnmThxIsuXL8fLy4t58+YRFhbG4cOHefzxx9m7dy8A0dHRjB49mjNnzvDCCy8QHx/vsO3T02vqRmQ2mxk3bhzBwcG4ubm5Oh3lQCLCnj17mDVrFqWlpZe3rCtixowZEhUVJYBERUXJ9OnT7dqYzWbJzc0Vs9ksJpNJcnNzxWQyCSCTJ0+WqVOnCiBubm7i4+MjgDz33HMye/ZsAeTxxx+XRYsWCSDt27eX1NRU8fLykuDgYMnJyRF3d/dqc7RYLFe8fa+BCIi7i/avhoYrYsqUKTJ48GDx8PBweS4ajg0PDw8ZMmSITJkyxe69S3x2uibhrKws8fPzE0D8/PwkKyvLrs2wYcNkzpw5xvScOXNk2LBhAsi+ffukUaNGdsusXr1aunbtauyUH3/8UQCJjo6W6OjoSttVFVdTdKaCnKoDfxgaGs6M2NhYLTg3UHh4eEhsbKzd/Oo+O112TcfX15eioiIAioqK8PX1tWvj7+9PQUGBMb1//378/f1p1qwZAFOnTmXHjh0sWbKEli1b2i1z5swZjh49io+PT5V9XWzMmDFYLBYsFgvNmze/4u3zQq/nqBuPm5sbZ86ccXUayknOnDlz2adRHVp0EhISyMjIsIshQ4bYtRWRGvfr6elJYGAgmzZtIiwsjM2bN/P222/XSs4xMTGEh4cTHh7OoUOHrrgfL/R6jlJKXcyhRadfv3506NDBLuLi4iguLsbPzw8APz8/SkpK7JYvLCwkMDDQmA4ICKCwsJDDhw/z888/s3z5cgCWLl1Kp06d7Jbx8PCgWbNmHD58uMq+HKUeeqSjlCucPn2alJQUI4KCgujVqxdlZWUkJyeTlZXF+vXreeCBB6rtZ8WKFWzevNlJWVfu2Wef5emnn66Vvl555RWb6Y0bN9ZKv1fCJecCZ86caTOQYMaMGXZtzGaz5OXliclkEpPJJHl5eWI2mwWQhQsXSp8+fQSQyMhIWbJkiQDypz/9yWYgweLFiwWQ2267zWYgQW5urkMHEnwMsr8OnHPV0HBmzJs3z+U5lJeX283r1auXrFq1ypju2LGj5Ofny7333ltpH82aNZN9+/bJzp07JSQkpNZyc3Nzq1P7xVG/8zo5kMDb21vWrl0rVqtVEhISjGISFhYmMTExRruRI0dKdna2ZGdny4gRI4z5rVu3lvXr10taWpqsXbtWAgMDBZD69evLkiVLJDs7W7Zu3WrzBzNhwgTJycmRrKwsGThw4CVzvJqi8xlIvov2rYaGq+LCD6D3QBJrOd6rQQ41KTpQ8dmyfPnySvsYOXKkfPjhh/L666/LK6+8YsyfO3euzJ49WywWi+zevVseeOABgYr/+H711VeSmJgoVqtVXn/9dQEkKChIsrKyJDY2VjIzM6V169Yyc+ZMycjIkPT0dHnssccEkFmzZslrr70mgPTv31/Wr18vbm5uMmnSJHn55ZcFkMTERHn33XfFYrHIzp07pXPnzrJs2TKxWq3GSF5AVqxYIdu3b5fMzEwZM2aMAPLmm2/K6dOnJSUlRb744gu7/VRZTr169ZLExERZunSp7Nq1y1iuut/5+aiTRedaiKspOvNBdteBbdDQcGbUhaJz/sM1JSXFKCqVFZ2OHTvKzp07K+0jPj5eevToIe3atZP09HRj/ty5c+Wbb74RNzc3ufnmm6WgoEDq168vkZGRcuDAAfH29pYGDRpIRkaGhIWFSVBQkJw5c0buuusuAeThhx+W+Ph4cXd3l5YtW8revXvFz89PGjZsKJmZmdK7d2/JysqSNm3aCGBXdM5/teSFF16QwsJC8fPzEy8vLykoKBBvb28BjP/An8/j/PyLi/H56apy6tWrl5SVlYm/v7+4ubnJpk2bpHv37tX+zs9HdZ+dLvty6PVOR6+pG92LLlrviRMnCA0NvWS7qkZdtWzZknbt2rFhwwYATp06xe23384PP/wAwJIlSxARcnJyyMvL47e//S1QMXDqyJEjACxfvpwePXrw1VdfsXfvXrZu3QpAjx49WLhwIWfPnqWkpIT169cTHh7OqlWrGDNmDN999x0vvvgieXl5leYWFxcHQEZGBj/88IMxAjgvL4/AwECOHDnCCy+8wEMPPQRAYGAg7dq1M9Zfmapy+umnn9i2bZtx7Ts1NZXg4OCrvhakt8FxEC06StVtoaGh7Nq1y27+Y489htlsJj8/n/z8fIKDg3niiSeM9y8eaXt+uqr5P//8c43y6dChA4cPH6ZVq1ZVtvnll18AOHv2rPHz+WlPT0969erFfffdR7du3bjzzjtJSUmhQYMGNVp/deuDiuHRnp5Xf5yiRcdBdMi0UnVXhw4deO211/jwww/t3nviiScYOHAgISEhhISEEBYWxrBhw4z3//CHP+Dm5kabNm1o06YNu3fvBipG65rNZho0aMCDDz5Y6RHB999/z+OPP467uzvNmzfnnnvuYdu2bbRu3ZqXX36Z0NBQ7r//frp06XJF29WsWTNKS0s5ceIEt956K127djXeO3XqVKVFo6qcHEVPrzmIDplWqm7p2bMnycnJNGrUiJKSEl544QXWrVtn0yYoKIigoCC2bNlizNuzZw9Hjx41CsG+ffvYtm0bN910E2PHjjWOBrZt28ayZcsICAjgiy++YMeOHQQFBdn0v2LFCrp160ZaWhoiwvjx4ykuLiYhIYG//e1vHDx4kNGjR/PZZ58RHh5+2du4evVqxo4dy86dO9m9e7fNdnz88cekp6eTnJzMU089dcmczp82dASXX3ysq3E1Awm+A1lbB7ZBQ8OZUReGTDsy5s6dK4888ojd/MjISPnggw9cnl9d+Z3XydvgXO/09JpSStnT02sOoqfXlLr+jBw5stL5sbGxxMbGOjmba5Me6TiIjl5TSil7WnQcRIuOUkrZ06LjIHpNRyml7GnRcRC9pqOUUva06DiInl5TyjXOP9ogIyODJUuW0LBhwyrbBgUF2dxt4GqVl5fXqN2AAQPYunUru3btIiUlhUWLFtk8euVK5Ofn4+PjA1zdYwsiIyP5zW9+c1W5VEeLjoPo6TWlXOP8vdc6dOjAyZMnGTt2bJVtg4ODefLJJy+rfw8Pj6vK7/bbb+eDDz4gMjKS9u3bExoayvz58wkODq61dXXv3v2K8xsxYkS1t+K5Wjpk2kH09JpS7wF31nKfqVzOrUS///577rjjDqZMmcKRI0d4//33AZg2bRolJSU88cQTtG/fnpSUFGJjY5k9ezazZ8+mc+fOnD59mpdeeomkpCQiIyN5+OGHadKkCR4eHjzwwAN88MEHdO7cGRFhypQpxkMlp02bxqBBgzhx4gRDhw61e0BlVFQUb7zxBllZWca8VatWGT8nJiaSmppq3IjTarXy6quv4uXlxeHDhxk+fDglJSV4e3uzcOFC/P392bx5s80NTMvLy2natCkAf/vb33jssceoX78+K1asYPLkyQQFBfHNN9+wYcMG7r77bgoLCxk6dCgPPPAAnTt3Zv78+Zw4cYJu3brx3//+93J/SdXSIx0H0dNrSrmWh4cH999/PxkZGfzrX/8iIiICqLi79LBhw/jiiy+Ijo7m+++/JzQ0lFmzZvHnP/8ZEeGOO+7giSeeIDY2lvr16wPQqVMnHn30UXr37s1rr73G0aNHueOOO+jYsaNxO50mTZqwZcsW7rzzTr777jvGjBljl9ftt99OcnJytbl7eXkRHh7Ou+++y4YNG+jatSudOnVi0aJFjB8/HoBJkyaxYcMGfve737FixQq7W+5Axf3g2rVrR5cuXbjzzjsJCwujZ8+eALRr144PP/yQ3/3ud5SVlfHII4+wbNkytm/fzvDhwwkNDa31ggN6pOMQ7lTsWD29pm5srnm4QcOGDUlJSQEqjnQ+/fRTTp06xeHDh7nzzjvx9fUlJSXFeAzBhXr06MEHH3wAwO7du9m7dy+33HILUPHogtLSUgDuu+8+m5uAlpWVARV3Zf73v/8NwI4dO+jXr1+1uXp7e/Ptt9/SqFEjPv74Y9555x0AFi9ebLQJCAhg8eLF/OY3v8HLy4v8/HwA7rnnHh5++GEA/vOf/1S6Pf3796d///7G/mjSpAnt2rVj37595Ofnk5aWZuRa2ek9R9Ci4wD1zr3qkY5SzlfV83Q++eQTRowYgZ+fH//6178uu9+aPKLg1Klf/6tZ1aMAfvjhBzp16kR6ejpHjhwhNDSUl19+mSZNmlS6rg8++IB3332XVatW0atXLyZPnlzjnN3c3HjzzTf5+OOPbeYHBQXZPbagugEXtUlPrzmAFh2l6p4VK1YwcOBAwsPDWbNmDWB77QMqjoyGDx8OVJx+at26tfHoggslJCTw5z//2Zg2mUw1zmPmzJlMnDjR5i7OjRo1qrJ9s2bNjAepRUZGGvO/++47YxDEwIED8fb2tlt2zZo1jBo1isaNGwPQqlUrWrRoUW1+F++T2qZFxwG8zr1q0VGq7jh16hSJiYksWbKEs2fPApCens6ZM2dITU1l3LhxfPTRR7i7u5Oens7ixYsZMWIEJ0/a/0ueNm0aZrOZjIwMUlNT6dOnT43zyMzM5K9//Svz5s0jKyuLDRs20L59exYsWFBp+8mTJ7N06VK2b9/OoUOHjPlTpkzhnnvuITMzk4cffpi9e/faLZuQkMCCBQvYvHkz6enpfPnll5csKJ999hlz5sy56gfAVcfpt8I2m80SHx8vVqtV4uPjxWQyVdouIiJCrFarWK1WiYiIMObXq1dP/vnPf8ru3btl165d8vDDDwsgL774ovzwww+SlpYma9euldatWxvLXPjc9JUrV9Yozyt9tEEzkEUg/evAbcc1NJwZdfnRBm5ubpKSkiI333yzy3O5nuJyH22AK5KcMWOGREVFCSBRUVEyffp0uzZms1lyc3PFbDaLyWSS3NxcozhNnjxZpk6dKlDxh+Tj4yOA9O7dWxo2bCiAjB07VhYtWmT0V15eftl5Xs3zdDQ0bsSoq0Wnffv2kpubK2+//bbLc7ne4pooOllZWeLn5yeA+Pn5SVZWll2bYcOGyZw5c4zpOXPmyLBhwwSQffv2SaNGjapdx5133ikbNmwwprXoaGg4Pupq0dFw7u+8zj3EzdfXl6KiIgCKiorw9fW1a+Pv709BQYExvX//fvz9/WnWrBkAU6dOZceOHSxZsoSWLVvaLT969Gi++eYbY7pBgwZYLBY2b97M0KFDq8xtzJgxWCwWLBYLzZs3v+JtVOpGJCJX/Y19de3w8PBARC5rGYcVnYSEBDIyMuxiyJAhdm0vJ2lPT08CAwPZtGkTYWFhbN68mbffftumzfDhw+ncuTNvvfWWMS8oKIjw8HCefPJJZs2aRZs2bSrtPyYmhvDwcMLDw20u2imlLm3Pnj088MADWnhuAOfvzLBnz57LWs5h39Op7ktRxcXF+Pn5UVRUhJ+fn91tIgAKCwvp3bu3MR0QEEBSUhKHDx/m559/Nm45sXTpUkaPHm2069u3LxMnTqRXr142o04OHDgAVNwULykpidDQUPLy8q52M5VSF5g1axbjxo3jkUcesbkti7r+iAh79uxh1qxZl7+ss2PmzJk2AwlmzJhh18ZsNkteXp6YTCYxmUySl5cnZrNZAFm4cKH06dNHAImMjJQlS5YIVFzHycnJsRudYjKZxMvLSwDx8fERq9Uq7du3v2Seek1HQ0ND4/Kjzg0k8Pb2lrVr14rVapWEhASjmISFhUlMTIzRbuTIkZKdnS3Z2dkyYsQIY37r1q1l/fr1xtDowMBAASQhIUGKiorshkZ369ZN0tPTJTU1VdLT02XUqFG1seM0NDQ0NCqJ6j473c79oCphsVgIDw93dRpKKXVNqe6zU+9IoJRSymn0SKcaJSUlld5a4lKaN29e50e+aY61Q3OsHZpj7akLeQYFBVX6VZbzXH7+73qLa+FakOaoOdal0BxvnDz19JpSSimn0aKjlFLKabToOMDFD0yqizTH2qE51g7NsfbU9Tx1IIFSSimn0SMdpZRSTqNFRymllNNo0alFAwYMICsri+zsbKKiolydDlBxo9R169bxww8/kJmZyQsvvACA2WwmPj4eq9VKfHz8ZT3j3VHc3d1JTk5m1apVAAQHB7Nlyxays7NZtGgR9erVc2l+zZo1Y+nSpezatYudO3fStWvXOrkfx40bR2ZmJhkZGSxYsID69eu7fF9++umnFBcXk5GRYcyrbt+9//77ZGdnk5aWRmhoqMtynDlzJrt27SItLY3ly5cbj1YBiI6OJjs7m6ysLPr37++yHM976aWXEBF8fHyMea7YjzXh8nHb10O4u7tLTk6OhISESL169SQ1NbVGNxV1dPj5+UloaKgA0qRJE9m9e7e0b9++Rk9vdXa8+OKLMn/+fFm1apUAsnjxYnn88ccFkNmzZ8vYsWNdmt9nn30mo0ePFqh4ZHqzZs3q3H5s1aqV5OXlSYMGDYx9GBkZ6fJ92bNnTwkNDZWMjAxjXlX77v7775f//Oc/Ashdd90lW7ZscVmO/fr1Ew8PDwFk+vTpRo7t27eX1NRU8fLykuDgYMnJyRF3d3eX5AhIQECArF69Wvbs2WM8SdlV+7EG4fIErovo2rWrrF692piOjo6W6Ohol+d1cXz11Vdy33331ejprc4Mf39/Wbt2rfTp08coOj/++KPxD/7i/evsuOmmmyQvL89ufl3bj61atZJ9+/aJ2WwWDw8PWbVqlfTv379O7MugoCCbD8uq9t2FTwm+uJ2zc7wwHnzwQfniiy8E7P99r169Wrp27eqyHJcuXSp33HGH5OfnG0XHlfuxutDTa7Wkqied1iVBQUGEhoaydevWGj291ZlmzZrF+PHjOXv2LAA+Pj6UlZVx5swZwPX7MyQkhB9//JG5c+eSnJxMTEwMjRo1qnP78cCBA7z99tvs27ePgwcPcvToUXbs2FGn9uV5Ve27uvpvadSoUcbTiOtSjkOGDKGwsJD09HSb+XUpxwtp0blBNG7cmGXLljFu3DjKy8vt3r/cR87WpgceeICSkhKSk5NdlsOleHp60qlTJ2bPnk2nTp34+eefiY6Otmvnyv0IYDKZGDp0KCEhIbRq1YrGjRszcOBAl+ZUU67ed9WZMGECp0+fZv78+a5OxUbDhg2ZMGECr7/+uqtTqTEtOrWksLCQwMBAYzogIIDCwkIXZvQrT09Pli1bxvz581mxYgXw69NbgSqf3uos3bt3Z8iQIeTn57No0SLuvfde3n//fUwmk/HYY1fvz/3797N//362bdsGwJdffkmnTp3q1H4EuO+++8jPz+fQoUOcPn2a5cuX07179zq1L8+rat/VtX9LkZGRDBo0iOHDhxvz6kqObdu2JSQkhLS0NPLz8wkICCA5ORlfX986k+PFtOjUEovFQrt27QgODqZevXoMGzaMuLg4V6cFVIx42bVrF++9954xLy4ujsjISKDiH9XKlStdlR4TJkwgMDCQkJAQhg0bxrp163jqqadITEzk0UcfrRM5FhcXU1BQwC233AJUPBZ9586ddWo/Auzbt4+uXbvSsGFD4Nc869K+PK+qfRcXF0dERAQAd911F0ePHjVOwznbgAEDGD9+PEOGDOHEiRPG/Li4OIYNG4aXlxfBwcG0a9fO+A+JM2VmZuLr60tISAghISHs37/f+M9QXdqPF3P5haXrJe6//37ZvXu35OTkyIQJE1yeDyDdu3cXEZG0tDTjiar3339/lU9vdXX06tXLGEgQEhIiW7dulezsbFmyZInxyHFXRceOHcVisUhaWpqsWLFCTCZTndyPkydPll27dklGRobMmzdPvLy8XL4vFyxYIAcOHJCTJ09KQUGBjBo1qtp993//93+Sk5Mj6enpEhYW5rIcs7OzZd++fca/ndmzZxvtJ0yYIDk5OZKVlSUDBw50WY4Xvn/hQAJX7cdLhd4GRymllNPo6TWllFJOo0VHKaWU02jRUUop5TRadJRSSjmNFh2llFJOo0VHqVoSFBRU6d1/LzR37lweeeQRAP76178a36epDUOHDqV9+/bG9JQpU+jbt2+t9a9UbdCio5SLjBs3jkaNGl3WMu7uVf+TffDBB7ntttuM6UmTJvHtt99ecX5KOYIWHaUcICQkhOTkZDp37lzp+3/5y19o1aoViYmJrFu3DoB+/fqxadMmduzYwZIlS2jcuDEA+fn5TJ8+nR07dvCHP/yBP/7xj2zbto3U1FS+/PJLGjZsSLdu3RgyZAhvvfUWKSkptGnTxuao6t577yU5OZn09HQ+/fRTvLy8jL4nT57Mjh07SE9P59ZbbwXgnnvuISUlhZSUFJKTk2nSpImjd5m6gbj8G6oaGtdDnL/l/C233CLJyclyxx132LWZO3euPPLIIwK23x738fGR9evXS6NGjQSQ8ePHy2uvvWa0+/vf/2704e3tbfw8depUef755+36vnC6fv36sm/fPmnXrp0AEhsbK3/961+Nvs8v/9xzz0lMTIwAEhcXJ3fffbcA0rhxY+OxCBoaVxt6pKNULWrRogUrV65k+PDhdrear07Xrl257bbb2LhxIykpKURGRhIUFGS8v3jxYuPn3/3ud3z33Xekp6czfPhwbr/99mr7vvXWW8nPzyc7OxuA2NhY7rnnHuP95cuXA7Bjxw6Cg4MB2LhxI++++y5/+ctfMJlMxmMRlLpaWnSUqkVHjx5l37599OjRA4B//etfpKSk8PXXX1e7nJubGwkJCYSGhhIaGsrtt9/OH//4R+P9n3/+2fj5s88+4/nnn+eOO+5gypQpNGjQ4Kpy/uWXXwA4c+YMnp6eAMyYMYM//vGPNGzYkI0bNxqn3ZS6Wp6uTkCp68nJkyd56KGHWLNmDceOHWPUqFFVti0vL6dp06YcPnyYLVu28OGHH9K2bVtyc3Np1KgR/v7+xtHJhZo2bcrBgwfx9PRk+PDhxu3qz/d3sd27dxMcHGz0/fTTT7N+/fpqt6NNmzZkZmaSmZlJeHg4v/3tb9m9e/dl7g2l7OmRjlK17Pjx4wwaNIgXX3yRwYMHV9nu448/ZvXq1axbt45Dhw4xYsQIFi5cSFpaGps3b+a3v/1tpcu99tprbN26lY0bN5KVlWXMX7RoEX//+99JTk6mTZs2xvxffvmFkSNHsnTpUtLT0zl79ixz5sypdhvGjRtHRkYGaWlpnDp1ynhiplJXS+8yrZRSymn0SEcppZTTaNFRSinlNFp0lFJKOY0WHaWUUk6jRUcppZTTaNFRSinlNFp0lFJKOc3/Aw8i8o9YTfCDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot result to see convergence\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1,k), dx2_dz3_list, c = \"red\", linestyle = \"solid\", label = \"FD Approximation\")\n",
    "\n",
    "plt.axhline(y = pytorch_grad2, color = 'blue', linestyle = '-', label = \"Pytorch Gradient\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Gradient Plot for dx2_dz3\")\n",
    "plt.ylabel(\"Gradient\")\n",
    "plt.xlabel(\"k-Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we confirmed that our model successfully computes the gradients, we go on to our third step: *Model Evaluation Set Up and Applications*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational inference with full model\n",
    "\n",
    "#### Definition of hyperparameters\n",
    "The first step is to define all options and hyperparameters for the inference task. Additional detail for each hyperparameter can be found in the [documentation](https://linfa-vi.readthedocs.io/en/latest/content/linfa_options.html) or in the definition of the [experiment](https://github.com/desResLab/LINFA/blob/master/linfa/run_experiment.py) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Setting\n",
    "exp = experiment()\n",
    "exp.flow_type        = 'maf'        # str: Type of flow\n",
    "exp.n_blocks         = 5            # int: Number of layers                            \n",
    "exp.hidden_size      = 100          # int: Hidden layer size for MADE in each layer  \n",
    "exp.n_hidden         = 1            # int: Number of hidden layers in each MADE      \n",
    "exp.activation_fn    = 'relu'       # str: Actication function used                  \n",
    "exp.input_order      = 'sequential' # str: Input order for create_mask           \n",
    "exp.batch_norm_order = True         # boolean: Order to decide if batch_norm is used    \n",
    "exp.save_interval    = 5000         # int: How often to sample from normalizing flow\n",
    "\n",
    "exp.input_size    = 3               # int: Dimensionality of input                   \n",
    "exp.batch_size    = 250             # int: Number of samples generated             \n",
    "exp.true_data_num = 2               # double: number of true model evaluated      \n",
    "exp.n_iter        = 25001           # int: Number of iterations                      \n",
    "exp.lr            = 0.01            # float: Learning rate                              \n",
    "exp.lr_decay      = 0.9999          # float: Learning rate decay                \n",
    "exp.log_interval  = 100             # int: How often to show loss stat   \n",
    "\n",
    "exp.run_nofas          = False      # boolean: to run experiment with nofas\n",
    "exp.annealing          = False      # boolean: to run experiment with annealing\n",
    "exp.calibrate_interval = 1000       # int: How often to update surrogate model     \n",
    "exp.budget             = 260        # int: Total number of true model evaluation\n",
    "\n",
    "exp.surr_pre_it  = 20000            # int: Number of pre-training iterations for surrogate model\n",
    "exp.surr_upd_it  = 6000             # int: Number of iterations for the surrogate model update\n",
    "exp.surr_folder  = \"./\"\n",
    "exp.use_new_surr = True             # boolean: to run experiment with nofas\n",
    "\n",
    "exp.results_file = 'results.txt'      # str: result text file name\n",
    "exp.log_file     = 'log.txt'          # str: log text file name\n",
    "exp.samples_file = 'samples.txt'      # str: sample text file name\n",
    "exp.seed         = random.randint(0, 10 ** 9)  # int: Random seed used\n",
    "exp.n_sample     = 5000               # int: Total number of iterations\n",
    "exp.no_cuda      = True               # boolean: to run experiment with NO cuda\n",
    "\n",
    "exp.optimizer    = 'RMSprop'          # str: Type of optimizer\n",
    "exp.lr_scheduler = 'ExponentialLR'    # str: Type of scheduler\n",
    "\n",
    "exp.device = torch.device('cuda:0' if torch.cuda.is_available() and not exp.no_cuda else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the transformation \n",
    "Now we define the trasformation of parameters and initialize the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation based on normalization rate\n",
    "trsf_info = [['identity',0.0,0.0,0.0,0.0],\n",
    "             ['identity',0.0,0.0,0.0,0.0],\n",
    "             ['linear',-3,3,30.0,80.0]]\n",
    "trsf = Transformation(trsf_info)        \n",
    "exp.transform = trsf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model and surrogate definition\n",
    "We create an instance of the **Phys** model and assign `None` to the surrogate. Note that we have also specified `exp.run_nofas = False` and `exp.annealing = False` to switch off both the adaptive surrogate capability and annealing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Phys()\n",
    "exp.model = model\n",
    "\n",
    "# Get data\n",
    "model.data = np.loadtxt('./data_phys_3d.txt')\n",
    "\n",
    "# Run experiment without surrogate\n",
    "exp.surrogate = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-likelihood definiton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define log density\n",
    "# x: original, untransformed inputs\n",
    "# model: our model\n",
    "# transform: our transformation \n",
    "def log_density(x, model, surrogate, transform):\n",
    "\n",
    "    # Compute transformation log Jacobian\n",
    "    adjust = transform.compute_log_jacob_func(x)\n",
    "\n",
    "    # Get the absolute values of the standard deviations\n",
    "    stds = torch.abs(model.solve_t(model.defParam)) * model.stdRatio\n",
    "    Data = torch.tensor(model.data).to(exp.device)\n",
    "    \n",
    "    # Check for surrogate\n",
    "    if surrogate:\n",
    "        modelOut = exp.surrogate.forward(x)\n",
    "    else:\n",
    "        modelOut = model.solve_t(transform.forward(x))\n",
    "\n",
    "    # Eval LL\n",
    "    ll1 = -0.5 * np.prod(model.data.shape) * np.log(2.0 * np.pi)\n",
    "    ll2 = (-0.5 * model.data.shape[1] * torch.log(torch.prod(stds))).item()\n",
    "    ll3 = 0.0\n",
    "    for i in range(3):\n",
    "        ll3 += - 0.5 * torch.sum(((modelOut[:, i].unsqueeze(1) - Data[i, :].unsqueeze(0)) / stds[0, i]) ** 2, dim=1)\n",
    "    negLL = -(ll1 + ll2 + ll3)\n",
    "    res = -negLL.reshape(x.size(0), 1) + adjust\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch inference task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TUTORIAL: Ballistic Example - Full model\n",
      "\n",
      "--- Running on device: cpu\n",
      "\n",
      "VI NF (t=1.000): it:     100 | loss: 8.097e+03\n",
      "VI NF (t=1.000): it:     200 | loss: 9.299e+03\n",
      "VI NF (t=1.000): it:     300 | loss: 7.961e+03\n",
      "VI NF (t=1.000): it:     400 | loss: 6.470e+03\n",
      "VI NF (t=1.000): it:     500 | loss: 5.325e+03\n",
      "VI NF (t=1.000): it:     600 | loss: 4.494e+03\n",
      "VI NF (t=1.000): it:     700 | loss: 3.778e+03\n",
      "VI NF (t=1.000): it:     800 | loss: 4.286e+02\n",
      "VI NF (t=1.000): it:     900 | loss: 2.082e+02\n",
      "VI NF (t=1.000): it:    1000 | loss: 1.999e+02\n",
      "VI NF (t=1.000): it:    1100 | loss: 1.658e+02\n",
      "VI NF (t=1.000): it:    1200 | loss: 1.270e+02\n",
      "VI NF (t=1.000): it:    1300 | loss: 3.964e+02\n",
      "VI NF (t=1.000): it:    1400 | loss: 1.304e+02\n",
      "VI NF (t=1.000): it:    1500 | loss: 9.628e+01\n",
      "VI NF (t=1.000): it:    1600 | loss: 6.986e+01\n",
      "VI NF (t=1.000): it:    1700 | loss: 6.151e+01\n",
      "VI NF (t=1.000): it:    1800 | loss: 2.051e+02\n",
      "VI NF (t=1.000): it:    1900 | loss: 4.543e+01\n",
      "VI NF (t=1.000): it:    2000 | loss: 3.550e+01\n",
      "VI NF (t=1.000): it:    2100 | loss: 3.140e+01\n",
      "VI NF (t=1.000): it:    2200 | loss: 2.939e+01\n",
      "VI NF (t=1.000): it:    2300 | loss: 2.797e+01\n",
      "VI NF (t=1.000): it:    2400 | loss: 2.869e+01\n",
      "VI NF (t=1.000): it:    2500 | loss: 2.811e+01\n",
      "VI NF (t=1.000): it:    2600 | loss: 2.933e+01\n",
      "VI NF (t=1.000): it:    2700 | loss: 2.814e+01\n",
      "VI NF (t=1.000): it:    2800 | loss: 2.975e+01\n",
      "VI NF (t=1.000): it:    2900 | loss: 2.743e+01\n",
      "VI NF (t=1.000): it:    3000 | loss: 2.784e+01\n",
      "VI NF (t=1.000): it:    3100 | loss: 2.752e+01\n",
      "VI NF (t=1.000): it:    3200 | loss: 2.789e+01\n",
      "VI NF (t=1.000): it:    3300 | loss: 2.791e+01\n",
      "VI NF (t=1.000): it:    3400 | loss: 2.695e+01\n",
      "VI NF (t=1.000): it:    3500 | loss: 2.703e+01\n",
      "VI NF (t=1.000): it:    3600 | loss: 2.766e+01\n",
      "VI NF (t=1.000): it:    3700 | loss: 2.683e+01\n",
      "VI NF (t=1.000): it:    3800 | loss: 2.686e+01\n",
      "VI NF (t=1.000): it:    3900 | loss: 2.681e+01\n",
      "VI NF (t=1.000): it:    4000 | loss: 2.727e+01\n",
      "VI NF (t=1.000): it:    4100 | loss: 2.714e+01\n",
      "VI NF (t=1.000): it:    4200 | loss: 2.677e+01\n",
      "VI NF (t=1.000): it:    4300 | loss: 2.743e+01\n",
      "VI NF (t=1.000): it:    4400 | loss: 2.719e+01\n",
      "VI NF (t=1.000): it:    4500 | loss: 2.706e+01\n",
      "VI NF (t=1.000): it:    4600 | loss: 2.655e+01\n",
      "VI NF (t=1.000): it:    4700 | loss: 2.667e+01\n",
      "VI NF (t=1.000): it:    4800 | loss: 2.668e+01\n",
      "VI NF (t=1.000): it:    4900 | loss: 2.679e+01\n",
      "--- Saving results at iteration 5000\n",
      "VI NF (t=1.000): it:    5000 | loss: 2.672e+01\n",
      "VI NF (t=1.000): it:    5100 | loss: 2.656e+01\n",
      "VI NF (t=1.000): it:    5200 | loss: 2.657e+01\n",
      "VI NF (t=1.000): it:    5300 | loss: 2.650e+01\n",
      "VI NF (t=1.000): it:    5400 | loss: 2.639e+01\n",
      "VI NF (t=1.000): it:    5500 | loss: 2.658e+01\n",
      "VI NF (t=1.000): it:    5600 | loss: 2.597e+01\n",
      "VI NF (t=1.000): it:    5700 | loss: 2.633e+01\n",
      "VI NF (t=1.000): it:    5800 | loss: 2.670e+01\n",
      "VI NF (t=1.000): it:    5900 | loss: 2.639e+01\n",
      "VI NF (t=1.000): it:    6000 | loss: 2.626e+01\n",
      "VI NF (t=1.000): it:    6100 | loss: 2.644e+01\n",
      "VI NF (t=1.000): it:    6200 | loss: 2.640e+01\n",
      "VI NF (t=1.000): it:    6300 | loss: 2.635e+01\n",
      "VI NF (t=1.000): it:    6400 | loss: 2.573e+01\n",
      "VI NF (t=1.000): it:    6500 | loss: 2.615e+01\n",
      "VI NF (t=1.000): it:    6600 | loss: 2.552e+01\n",
      "VI NF (t=1.000): it:    6700 | loss: 2.569e+01\n",
      "VI NF (t=1.000): it:    6800 | loss: 2.552e+01\n",
      "VI NF (t=1.000): it:    6900 | loss: 2.606e+01\n",
      "VI NF (t=1.000): it:    7000 | loss: 2.694e+01\n",
      "VI NF (t=1.000): it:    7100 | loss: 2.571e+01\n",
      "VI NF (t=1.000): it:    7200 | loss: 2.505e+01\n",
      "VI NF (t=1.000): it:    7300 | loss: 2.532e+01\n",
      "VI NF (t=1.000): it:    7400 | loss: 2.554e+01\n",
      "VI NF (t=1.000): it:    7500 | loss: 2.516e+01\n",
      "VI NF (t=1.000): it:    7600 | loss: 2.508e+01\n",
      "VI NF (t=1.000): it:    7700 | loss: 2.481e+01\n",
      "VI NF (t=1.000): it:    7800 | loss: 2.490e+01\n",
      "VI NF (t=1.000): it:    7900 | loss: 2.503e+01\n",
      "VI NF (t=1.000): it:    8000 | loss: 2.523e+01\n",
      "VI NF (t=1.000): it:    8100 | loss: 2.581e+01\n",
      "VI NF (t=1.000): it:    8200 | loss: 2.535e+01\n",
      "VI NF (t=1.000): it:    8300 | loss: 2.486e+01\n",
      "VI NF (t=1.000): it:    8400 | loss: 2.519e+01\n",
      "VI NF (t=1.000): it:    8500 | loss: 2.494e+01\n",
      "VI NF (t=1.000): it:    8600 | loss: 2.542e+01\n",
      "VI NF (t=1.000): it:    8700 | loss: 2.469e+01\n",
      "VI NF (t=1.000): it:    8800 | loss: 2.605e+01\n",
      "VI NF (t=1.000): it:    8900 | loss: 2.513e+01\n",
      "VI NF (t=1.000): it:    9000 | loss: 2.471e+01\n",
      "VI NF (t=1.000): it:    9100 | loss: 2.492e+01\n",
      "VI NF (t=1.000): it:    9200 | loss: 2.476e+01\n",
      "VI NF (t=1.000): it:    9300 | loss: 2.513e+01\n",
      "VI NF (t=1.000): it:    9400 | loss: 2.478e+01\n",
      "VI NF (t=1.000): it:    9500 | loss: 2.475e+01\n",
      "VI NF (t=1.000): it:    9600 | loss: 2.450e+01\n",
      "VI NF (t=1.000): it:    9700 | loss: 2.478e+01\n",
      "VI NF (t=1.000): it:    9800 | loss: 2.451e+01\n",
      "VI NF (t=1.000): it:    9900 | loss: 2.492e+01\n",
      "--- Saving results at iteration 10000\n",
      "VI NF (t=1.000): it:   10000 | loss: 2.481e+01\n",
      "VI NF (t=1.000): it:   10100 | loss: 2.499e+01\n",
      "VI NF (t=1.000): it:   10200 | loss: 2.449e+01\n",
      "VI NF (t=1.000): it:   10300 | loss: 2.453e+01\n",
      "VI NF (t=1.000): it:   10400 | loss: 2.463e+01\n",
      "VI NF (t=1.000): it:   10500 | loss: 2.644e+01\n",
      "VI NF (t=1.000): it:   10600 | loss: 2.447e+01\n",
      "VI NF (t=1.000): it:   10700 | loss: 2.450e+01\n",
      "VI NF (t=1.000): it:   10800 | loss: 2.453e+01\n",
      "VI NF (t=1.000): it:   10900 | loss: 2.488e+01\n",
      "VI NF (t=1.000): it:   11000 | loss: 2.449e+01\n",
      "VI NF (t=1.000): it:   11100 | loss: 2.472e+01\n",
      "VI NF (t=1.000): it:   11200 | loss: 2.450e+01\n",
      "VI NF (t=1.000): it:   11300 | loss: 2.470e+01\n",
      "VI NF (t=1.000): it:   11400 | loss: 2.635e+01\n",
      "VI NF (t=1.000): it:   11500 | loss: 2.464e+01\n",
      "VI NF (t=1.000): it:   11600 | loss: 2.517e+01\n",
      "VI NF (t=1.000): it:   11700 | loss: 2.429e+01\n",
      "VI NF (t=1.000): it:   11800 | loss: 2.494e+01\n",
      "VI NF (t=1.000): it:   11900 | loss: 2.445e+01\n",
      "VI NF (t=1.000): it:   12000 | loss: 2.499e+01\n",
      "VI NF (t=1.000): it:   12100 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   12200 | loss: 2.431e+01\n",
      "VI NF (t=1.000): it:   12300 | loss: 2.441e+01\n",
      "VI NF (t=1.000): it:   12400 | loss: 2.485e+01\n",
      "VI NF (t=1.000): it:   12500 | loss: 2.453e+01\n",
      "VI NF (t=1.000): it:   12600 | loss: 2.503e+01\n",
      "VI NF (t=1.000): it:   12700 | loss: 2.418e+01\n",
      "VI NF (t=1.000): it:   12800 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   12900 | loss: 2.427e+01\n",
      "VI NF (t=1.000): it:   13000 | loss: 2.412e+01\n",
      "VI NF (t=1.000): it:   13100 | loss: 2.456e+01\n",
      "VI NF (t=1.000): it:   13200 | loss: 2.560e+01\n",
      "VI NF (t=1.000): it:   13300 | loss: 2.409e+01\n",
      "VI NF (t=1.000): it:   13400 | loss: 2.420e+01\n",
      "VI NF (t=1.000): it:   13500 | loss: 2.427e+01\n",
      "VI NF (t=1.000): it:   13600 | loss: 2.681e+01\n",
      "VI NF (t=1.000): it:   13700 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   13800 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   13900 | loss: 2.406e+01\n",
      "VI NF (t=1.000): it:   14000 | loss: 2.416e+01\n",
      "VI NF (t=1.000): it:   14100 | loss: 2.423e+01\n",
      "VI NF (t=1.000): it:   14200 | loss: 2.425e+01\n",
      "VI NF (t=1.000): it:   14300 | loss: 2.406e+01\n",
      "VI NF (t=1.000): it:   14400 | loss: 2.415e+01\n",
      "VI NF (t=1.000): it:   14500 | loss: 2.412e+01\n",
      "VI NF (t=1.000): it:   14600 | loss: 2.431e+01\n",
      "VI NF (t=1.000): it:   14700 | loss: 2.457e+01\n",
      "VI NF (t=1.000): it:   14800 | loss: 2.455e+01\n",
      "VI NF (t=1.000): it:   14900 | loss: 2.438e+01\n",
      "--- Saving results at iteration 15000\n",
      "VI NF (t=1.000): it:   15000 | loss: 2.434e+01\n",
      "VI NF (t=1.000): it:   15100 | loss: 2.404e+01\n",
      "VI NF (t=1.000): it:   15200 | loss: 2.391e+01\n",
      "VI NF (t=1.000): it:   15300 | loss: 2.417e+01\n",
      "VI NF (t=1.000): it:   15400 | loss: 2.402e+01\n",
      "VI NF (t=1.000): it:   15500 | loss: 2.450e+01\n",
      "VI NF (t=1.000): it:   15600 | loss: 2.388e+01\n",
      "VI NF (t=1.000): it:   15700 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   15800 | loss: 2.404e+01\n",
      "VI NF (t=1.000): it:   15900 | loss: 2.407e+01\n",
      "VI NF (t=1.000): it:   16000 | loss: 2.399e+01\n",
      "VI NF (t=1.000): it:   16100 | loss: 2.400e+01\n",
      "VI NF (t=1.000): it:   16200 | loss: 2.395e+01\n",
      "VI NF (t=1.000): it:   16300 | loss: 2.400e+01\n",
      "VI NF (t=1.000): it:   16400 | loss: 2.447e+01\n",
      "VI NF (t=1.000): it:   16500 | loss: 2.412e+01\n",
      "VI NF (t=1.000): it:   16600 | loss: 2.404e+01\n",
      "VI NF (t=1.000): it:   16700 | loss: 2.390e+01\n",
      "VI NF (t=1.000): it:   16800 | loss: 2.405e+01\n",
      "VI NF (t=1.000): it:   16900 | loss: 2.389e+01\n",
      "VI NF (t=1.000): it:   17000 | loss: 2.395e+01\n",
      "VI NF (t=1.000): it:   17100 | loss: 2.403e+01\n",
      "VI NF (t=1.000): it:   17200 | loss: 2.418e+01\n",
      "VI NF (t=1.000): it:   17300 | loss: 2.447e+01\n",
      "VI NF (t=1.000): it:   17400 | loss: 2.392e+01\n",
      "VI NF (t=1.000): it:   17500 | loss: 2.382e+01\n",
      "VI NF (t=1.000): it:   17600 | loss: 2.424e+01\n",
      "VI NF (t=1.000): it:   17700 | loss: 2.389e+01\n",
      "VI NF (t=1.000): it:   17800 | loss: 2.379e+01\n",
      "VI NF (t=1.000): it:   17900 | loss: 2.403e+01\n",
      "VI NF (t=1.000): it:   18000 | loss: 2.399e+01\n",
      "VI NF (t=1.000): it:   18100 | loss: 2.383e+01\n",
      "VI NF (t=1.000): it:   18200 | loss: 2.420e+01\n",
      "VI NF (t=1.000): it:   18300 | loss: 2.410e+01\n",
      "VI NF (t=1.000): it:   18400 | loss: 2.392e+01\n",
      "VI NF (t=1.000): it:   18500 | loss: 2.387e+01\n",
      "VI NF (t=1.000): it:   18600 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   18700 | loss: 2.384e+01\n",
      "VI NF (t=1.000): it:   18800 | loss: 2.477e+01\n",
      "VI NF (t=1.000): it:   18900 | loss: 2.389e+01\n",
      "VI NF (t=1.000): it:   19000 | loss: 2.382e+01\n",
      "VI NF (t=1.000): it:   19100 | loss: 2.390e+01\n",
      "VI NF (t=1.000): it:   19200 | loss: 2.392e+01\n",
      "VI NF (t=1.000): it:   19300 | loss: 2.389e+01\n",
      "VI NF (t=1.000): it:   19400 | loss: 2.378e+01\n",
      "VI NF (t=1.000): it:   19500 | loss: 2.386e+01\n",
      "VI NF (t=1.000): it:   19600 | loss: 2.388e+01\n",
      "VI NF (t=1.000): it:   19700 | loss: 2.381e+01\n",
      "VI NF (t=1.000): it:   19800 | loss: 2.390e+01\n",
      "VI NF (t=1.000): it:   19900 | loss: 2.401e+01\n",
      "--- Saving results at iteration 20000\n",
      "VI NF (t=1.000): it:   20000 | loss: 2.398e+01\n",
      "VI NF (t=1.000): it:   20100 | loss: 2.376e+01\n",
      "VI NF (t=1.000): it:   20200 | loss: 2.403e+01\n",
      "VI NF (t=1.000): it:   20300 | loss: 2.382e+01\n",
      "VI NF (t=1.000): it:   20400 | loss: 2.388e+01\n",
      "VI NF (t=1.000): it:   20500 | loss: 2.373e+01\n",
      "VI NF (t=1.000): it:   20600 | loss: 2.381e+01\n",
      "VI NF (t=1.000): it:   20700 | loss: 2.387e+01\n",
      "VI NF (t=1.000): it:   20800 | loss: 2.369e+01\n",
      "VI NF (t=1.000): it:   20900 | loss: 2.387e+01\n",
      "VI NF (t=1.000): it:   21000 | loss: 2.362e+01\n",
      "VI NF (t=1.000): it:   21100 | loss: 2.386e+01\n",
      "VI NF (t=1.000): it:   21200 | loss: 2.369e+01\n",
      "VI NF (t=1.000): it:   21300 | loss: 2.386e+01\n",
      "VI NF (t=1.000): it:   21400 | loss: 2.374e+01\n",
      "VI NF (t=1.000): it:   21500 | loss: 2.365e+01\n",
      "VI NF (t=1.000): it:   21600 | loss: 2.362e+01\n",
      "VI NF (t=1.000): it:   21700 | loss: 2.360e+01\n",
      "VI NF (t=1.000): it:   21800 | loss: 2.364e+01\n",
      "VI NF (t=1.000): it:   21900 | loss: 2.375e+01\n",
      "VI NF (t=1.000): it:   22000 | loss: 2.422e+01\n",
      "VI NF (t=1.000): it:   22100 | loss: 2.403e+01\n",
      "VI NF (t=1.000): it:   22200 | loss: 2.352e+01\n",
      "VI NF (t=1.000): it:   22300 | loss: 2.363e+01\n",
      "VI NF (t=1.000): it:   22400 | loss: 2.365e+01\n",
      "VI NF (t=1.000): it:   22500 | loss: 2.374e+01\n",
      "VI NF (t=1.000): it:   22600 | loss: 2.373e+01\n",
      "VI NF (t=1.000): it:   22700 | loss: 2.378e+01\n",
      "VI NF (t=1.000): it:   22800 | loss: 2.353e+01\n",
      "VI NF (t=1.000): it:   22900 | loss: 2.379e+01\n",
      "VI NF (t=1.000): it:   23000 | loss: 2.375e+01\n",
      "VI NF (t=1.000): it:   23100 | loss: 2.379e+01\n",
      "VI NF (t=1.000): it:   23200 | loss: 2.389e+01\n",
      "VI NF (t=1.000): it:   23300 | loss: 2.362e+01\n",
      "VI NF (t=1.000): it:   23400 | loss: 2.398e+01\n",
      "VI NF (t=1.000): it:   23500 | loss: 2.366e+01\n",
      "VI NF (t=1.000): it:   23600 | loss: 2.379e+01\n",
      "VI NF (t=1.000): it:   23700 | loss: 2.359e+01\n",
      "VI NF (t=1.000): it:   23800 | loss: 2.390e+01\n",
      "VI NF (t=1.000): it:   23900 | loss: 2.368e+01\n",
      "VI NF (t=1.000): it:   24000 | loss: 2.382e+01\n",
      "VI NF (t=1.000): it:   24100 | loss: 2.347e+01\n",
      "VI NF (t=1.000): it:   24200 | loss: 2.380e+01\n",
      "VI NF (t=1.000): it:   24300 | loss: 2.364e+01\n",
      "VI NF (t=1.000): it:   24400 | loss: 2.360e+01\n",
      "VI NF (t=1.000): it:   24500 | loss: 2.356e+01\n",
      "VI NF (t=1.000): it:   24600 | loss: 2.376e+01\n",
      "VI NF (t=1.000): it:   24700 | loss: 2.379e+01\n",
      "VI NF (t=1.000): it:   24800 | loss: 2.376e+01\n",
      "VI NF (t=1.000): it:   24900 | loss: 2.366e+01\n",
      "--- Saving results at iteration 25000\n",
      "VI NF (t=1.000): it:   25000 | loss: 2.360e+01\n",
      "\n",
      "--- Simulation completed!\n"
     ]
    }
   ],
   "source": [
    "## Run \n",
    "print('')\n",
    "print('--- TUTORIAL: Ballistic Example - Full model')\n",
    "\n",
    "# Experiment Setting\n",
    "exp.name = \"phys_full_3d\"             # str: Name of experiment\n",
    "exp.output_dir   = './' + exp.name    # str: output directory location\n",
    "\n",
    "# Assign logdensity\n",
    "exp.model_logdensity = lambda x: log_density(x, model, exp.surrogate, trsf)\n",
    "\n",
    "# Run VI\n",
    "exp.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model evaluation has been successfully completed by checking at the newly created **phys_nofasFree** folder in the tutorial directory.\n",
    "\n",
    "Note also that LINFA supports a post processing script to plot the mnain results including the loss profile, two-dimensional slices of the posterior distribution and two-dimensional slices for the predictive posterior.\n",
    "\n",
    "We can use the command below to generate the result plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b81b3651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting log...\n",
      "Plotting posterior samples...\n",
      "Plotting posterior predictive samples...\n"
     ]
    }
   ],
   "source": [
    "import linfa\n",
    "! python3 -m linfa.plot_res -n phys_full_3d -i 25000 -f \"./\" -p 'png' -d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea37353b",
   "metadata": {},
   "source": [
    "You can now visualize the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df0bd68d",
   "metadata": {},
   "source": [
    "<center><img src=./phys_full_3d/log_plot.png width=300 /></center></br>\n",
    "\n",
    "<center> <b>Figure:</b> Loss profile</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6cc34a",
   "metadata": {},
   "source": [
    "<center><img src=\"phys_full_3d/data_plot_phys_full_3d_25000_0_1.png\" width=400>\n",
    "<img src=\"phys_full_3d/data_plot_phys_full_3d_25000_0_2.png\" width=400>\n",
    "<img src=\"phys_full_3d/data_plot_phys_full_3d_25000_1_2.png\" width=400></center></br>\n",
    "\n",
    "<center> <b>Figure:</b> Two-dimensional slices from predictive posterior distribution.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b49f515",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./phys_full 3d/params_plot_phys_full_3d_25000_0_1.png\" width=400>\n",
    "<img src=\"./phys_full_3d/params_plot_phys_full_3d_25000_0_2.png\" width=400>\n",
    "<img src=\"./phys_full_3d/params_plot_phys_full_3d_25000_1_2.png\" width=400>\n",
    "</center></br>\n",
    "\n",
    "<center> <b>Figure:</b> Two-dimensional slices from posterior distribution.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63ccf4cd",
   "metadata": {},
   "source": [
    "However, even with our simple model, the cost of evaluating the physics-based model and to compute the gradient through it can be significant and might lead to intractable inference tasks.\n",
    "\n",
    "In such cases, LINFA enables the construction of the adaptively trained surrogate model. By utilizing the surrogate model, gradient computation is executed through the surrogate, reducing the computational burden of such operation.\n",
    "\n",
    "In addition, LINFA provides an adaptive annealing scheduler (AdaAnn) which allows easier sampling from complicated densities.\n",
    "\n",
    "Accordingly, we will specifically observe how the adaptively trained surrogate model reduces the computational cost in our last step: <br>\n",
    "*Applying our model including the Surrogate model.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e705547e",
   "metadata": {},
   "source": [
    "### AdaAnn: An adaptive annealing scheduler\n",
    "\n",
    "We start by additing some options to activate the adaptive annealing scheduler and specify the associated hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9ab54cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.annealing = True\n",
    "exp.scheduler = 'AdaAnn' # str: type of annealing scheduler used\n",
    "exp.tol       = 0.01     # float: tolerance for AdaAnn scheduler\n",
    "exp.t0        = 0.05     # float: initial inverse temperature value\n",
    "exp.N         = 100      # int: number of sample points during annealing\n",
    "exp.N_1       = 100      # int: number of sample points at t=1\n",
    "exp.T_0       = 500      # int: number of parameter updates at initial t0\n",
    "exp.T         = 5        # int: number of parameter updates during annealing\n",
    "exp.T_1       = 25000    # int: number of parameter updates at t=1\n",
    "exp.M         = 1000     # int: number of sample points used to update temperature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NoFAS: Normalizing flow with an adaptively trained surrogate\n",
    "\n",
    "Before specifying a surrogate model, we define the associated hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48ae6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_nofas          = True       # boolean: to run experiment with nofas\n",
    "exp.calibrate_interval = 1000       # int: How often to update surrogate model     \n",
    "exp.budget             = 1000       # int: Total number of true model evaluation\n",
    "exp.surr_pre_it        = 20000      # int: Number of pre-training iterations for surrogate model\n",
    "exp.surr_upd_it        = 6000       # int: Number of iterations for the surrogate model update\n",
    "exp.use_new_surr       = True       # boolean: to run experiment with nofas\n",
    "exp.surr_folder        = \"./\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3b34aae",
   "metadata": {},
   "source": [
    "In addition we need to define the new surrogate and assign the surrogate so the current instance of th *Experiment* class knows about it. \n",
    "Note the following hyperparameter choices:\n",
    "\n",
    "* The `memory_len` parameter is set to 100 to use the adaptively collected samples for a larger number of iterations. \n",
    "\n",
    "* A parametric architecture can be specified for the default dense neural network surrogate. The parameter `architednn_arch=[64,32]` is used to generate a dense neural network with two hidden layers having 64 and 32 neurons, respectively. The parameter `dnn_activation='tanh'` is used to specify a `tanh` activation function for all layers except the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Pre-Grid found.\n",
      "Warning: Surrogate model files: ./phys_surr_3d.npz and ./phys_surr_3d.npz could not be found. \n",
      "\n",
      "--- Pre-training surrogate model\n",
      "\n",
      "SUR: PRE: it:       0 | loss: 3.043e+00\n",
      "SUR: PRE: it:     500 | loss: 8.703e-02\n",
      "SUR: PRE: it:    1000 | loss: 4.943e-02\n",
      "SUR: PRE: it:    1500 | loss: 3.882e-02\n",
      "SUR: PRE: it:    2000 | loss: 4.243e-02\n",
      "SUR: PRE: it:    2500 | loss: 3.188e-02\n",
      "SUR: PRE: it:    3000 | loss: 1.815e-02\n",
      "SUR: PRE: it:    3500 | loss: 4.714e-02\n",
      "SUR: PRE: it:    4000 | loss: 1.351e-02\n",
      "SUR: PRE: it:    4500 | loss: 1.602e-02\n",
      "SUR: PRE: it:    5000 | loss: 2.095e-02\n",
      "SUR: PRE: it:    5500 | loss: 9.381e-03\n",
      "SUR: PRE: it:    6000 | loss: 4.442e-02\n",
      "SUR: PRE: it:    6500 | loss: 6.420e-03\n",
      "SUR: PRE: it:    7000 | loss: 1.267e-02\n",
      "SUR: PRE: it:    7500 | loss: 2.956e-03\n",
      "SUR: PRE: it:    8000 | loss: 4.290e-03\n",
      "SUR: PRE: it:    8500 | loss: 1.789e-02\n",
      "SUR: PRE: it:    9000 | loss: 9.112e-03\n",
      "SUR: PRE: it:    9500 | loss: 1.393e-02\n",
      "SUR: PRE: it:   10000 | loss: 4.573e-03\n",
      "SUR: PRE: it:   10500 | loss: 1.488e-03\n",
      "SUR: PRE: it:   11000 | loss: 5.723e-03\n",
      "SUR: PRE: it:   11500 | loss: 4.364e-03\n",
      "SUR: PRE: it:   12000 | loss: 2.357e-03\n",
      "SUR: PRE: it:   12500 | loss: 1.344e-02\n",
      "SUR: PRE: it:   13000 | loss: 1.483e-03\n",
      "SUR: PRE: it:   13500 | loss: 9.106e-03\n",
      "SUR: PRE: it:   14000 | loss: 8.593e-03\n",
      "SUR: PRE: it:   14500 | loss: 3.896e-03\n",
      "SUR: PRE: it:   15000 | loss: 4.086e-03\n",
      "SUR: PRE: it:   15500 | loss: 3.845e-03\n",
      "SUR: PRE: it:   16000 | loss: 3.169e-03\n",
      "SUR: PRE: it:   16500 | loss: 7.166e-03\n",
      "SUR: PRE: it:   17000 | loss: 3.950e-03\n",
      "SUR: PRE: it:   17500 | loss: 1.705e-03\n",
      "SUR: PRE: it:   18000 | loss: 1.396e-03\n",
      "SUR: PRE: it:   18500 | loss: 1.115e-03\n",
      "SUR: PRE: it:   19000 | loss: 9.642e-04\n",
      "SUR: PRE: it:   19500 | loss: 1.315e-03\n",
      "\n",
      "--- Surrogate model pre-train complete\n",
      "\n",
      "Success: [limits] loaded.\n",
      "Success: [pre_grid] loaded.\n",
      "Success: [grid_record] loaded.\n"
     ]
    }
   ],
   "source": [
    "exp.name = \"phys_surr_3d\"\n",
    "exp.output_dir   = './' + exp.name\n",
    "\n",
    "exp.surrogate = Surrogate(exp.name, lambda x: model.solve_t(trsf.forward(x)), exp.input_size, 3, \n",
    "                            model_folder=exp.surr_folder, limits=torch.Tensor([[0, 6], [4, 8], [-3, 3]]), \n",
    "                            memory_len=100, dnn_arch=[64,32], dnn_activation='tanh', device=exp.device)\n",
    "surr_filename = exp.surr_folder + exp.name\n",
    "if exp.use_new_surr or (not os.path.isfile(surr_filename + \".sur\")) or (not os.path.isfile(surr_filename + \".npz\")):\n",
    "    print(\"Warning: Surrogate model files: {0}.npz and {0}.npz could not be found. \".format(surr_filename))\n",
    "    exp.surrogate.gen_grid(gridnum=5)\n",
    "    exp.surrogate.pre_train(exp.surr_pre_it, 0.03, 0.9999, 500, store=True)\n",
    "# Load the surrogate\n",
    "exp.surrogate.surrogate_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TUTORIAL: Ballistic Example - with NN surrogate and annealing\n",
      "\n",
      "--- Running on device: cpu\n",
      "\n",
      "VI NF (t=0.050): it:     100 | loss: 8.693e+02\n",
      "VI NF (t=0.050): it:     200 | loss: 4.097e+02\n",
      "VI NF (t=0.050): it:     300 | loss: 1.896e+02\n",
      "VI NF (t=0.050): it:     400 | loss: 4.922e+01\n",
      "VI NF (t=0.050): it:     500 | loss: 1.525e+01\n",
      "VI NF (t=0.054): it:     600 | loss: 1.064e+01\n",
      "VI NF (t=0.058): it:     700 | loss: 1.001e+01\n",
      "VI NF (t=0.063): it:     800 | loss: 1.040e+01\n",
      "VI NF (t=0.069): it:     900 | loss: 9.756e+00\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "7.424e-02 -> 3.584e-02\n",
      "2.500e-02 -> 1.707e-01\n",
      "1.380e-01 -> 1.380e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 1.559e-02\n",
      "SUR: UPD: it:     500 | loss: 3.806e-03\n",
      "SUR: UPD: it:    1000 | loss: 2.288e-03\n",
      "SUR: UPD: it:    1500 | loss: 1.092e-03\n",
      "SUR: UPD: it:    2000 | loss: 1.144e-03\n",
      "SUR: UPD: it:    2500 | loss: 1.011e-03\n",
      "SUR: UPD: it:    3000 | loss: 8.983e-04\n",
      "SUR: UPD: it:    3500 | loss: 8.749e-04\n",
      "SUR: UPD: it:    4000 | loss: 8.585e-04\n",
      "SUR: UPD: it:    4500 | loss: 8.378e-04\n",
      "SUR: UPD: it:    5000 | loss: 7.632e-04\n",
      "SUR: UPD: it:    5500 | loss: 7.191e-04\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=0.076): it:    1000 | loss: 2.362e+01\n",
      "VI NF (t=0.083): it:    1100 | loss: 1.111e+01\n",
      "VI NF (t=0.090): it:    1200 | loss: 9.426e+00\n",
      "VI NF (t=0.099): it:    1300 | loss: 1.514e+01\n",
      "VI NF (t=0.108): it:    1400 | loss: 1.193e+01\n",
      "VI NF (t=0.116): it:    1500 | loss: 1.104e+01\n",
      "VI NF (t=0.125): it:    1600 | loss: 1.127e+01\n",
      "VI NF (t=0.138): it:    1700 | loss: 1.174e+01\n",
      "VI NF (t=0.148): it:    1800 | loss: 1.011e+01\n",
      "VI NF (t=0.161): it:    1900 | loss: 1.326e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "6.575e-01 -> 6.575e-01\n",
      "1.438e+00 -> 1.438e+00\n",
      "2.043e+00 -> 2.043e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 1.269e+00\n",
      "SUR: UPD: it:     500 | loss: 8.159e-03\n",
      "SUR: UPD: it:    1000 | loss: 7.354e-03\n",
      "SUR: UPD: it:    1500 | loss: 4.894e-03\n",
      "SUR: UPD: it:    2000 | loss: 4.068e-03\n",
      "SUR: UPD: it:    2500 | loss: 3.469e-03\n",
      "SUR: UPD: it:    3000 | loss: 3.312e-03\n",
      "SUR: UPD: it:    3500 | loss: 3.131e-03\n",
      "SUR: UPD: it:    4000 | loss: 3.077e-03\n",
      "SUR: UPD: it:    4500 | loss: 3.041e-03\n",
      "SUR: UPD: it:    5000 | loss: 3.012e-03\n",
      "SUR: UPD: it:    5500 | loss: 2.991e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=0.175): it:    2000 | loss: 2.523e+02\n",
      "VI NF (t=0.176): it:    2100 | loss: 2.788e+01\n",
      "VI NF (t=0.177): it:    2200 | loss: 2.433e+01\n",
      "VI NF (t=0.177): it:    2300 | loss: 4.982e+01\n",
      "VI NF (t=0.177): it:    2400 | loss: 2.616e+01\n",
      "VI NF (t=0.177): it:    2500 | loss: 4.490e+01\n",
      "VI NF (t=0.177): it:    2600 | loss: 2.615e+01\n",
      "VI NF (t=0.177): it:    2700 | loss: 2.154e+01\n",
      "VI NF (t=0.178): it:    2800 | loss: 2.656e+01\n",
      "VI NF (t=0.179): it:    2900 | loss: 3.158e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "5.720e-02 -> 1.746e-02\n",
      "4.953e-02 -> 1.434e-01\n",
      "7.702e-02 -> 7.042e-02\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 5.943e-03\n",
      "SUR: UPD: it:     500 | loss: 3.086e-02\n",
      "SUR: UPD: it:    1000 | loss: 9.897e-03\n",
      "SUR: UPD: it:    1500 | loss: 7.404e-03\n",
      "SUR: UPD: it:    2000 | loss: 5.710e-03\n",
      "SUR: UPD: it:    2500 | loss: 5.252e-03\n",
      "SUR: UPD: it:    3000 | loss: 4.513e-03\n",
      "SUR: UPD: it:    3500 | loss: 4.288e-03\n",
      "SUR: UPD: it:    4000 | loss: 4.126e-03\n",
      "SUR: UPD: it:    4500 | loss: 4.000e-03\n",
      "SUR: UPD: it:    5000 | loss: 3.917e-03\n",
      "SUR: UPD: it:    5500 | loss: 3.864e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=0.182): it:    3000 | loss: 2.595e+01\n",
      "VI NF (t=0.190): it:    3100 | loss: 1.541e+01\n",
      "VI NF (t=0.208): it:    3200 | loss: 1.179e+01\n",
      "VI NF (t=0.228): it:    3300 | loss: 1.253e+01\n",
      "VI NF (t=0.251): it:    3400 | loss: 1.268e+01\n",
      "VI NF (t=0.279): it:    3500 | loss: 1.373e+01\n",
      "VI NF (t=0.301): it:    3600 | loss: 1.398e+01\n",
      "VI NF (t=0.338): it:    3700 | loss: 1.595e+01\n",
      "VI NF (t=0.367): it:    3800 | loss: 1.501e+01\n",
      "VI NF (t=0.401): it:    3900 | loss: 1.531e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "2.474e-02 -> 3.858e-03\n",
      "8.233e-03 -> 3.173e-02\n",
      "4.535e-02 -> 1.293e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 4.924e-03\n",
      "SUR: UPD: it:     500 | loss: 1.643e-02\n",
      "SUR: UPD: it:    1000 | loss: 9.051e-03\n",
      "SUR: UPD: it:    1500 | loss: 5.473e-03\n",
      "SUR: UPD: it:    2000 | loss: 6.404e-03\n",
      "SUR: UPD: it:    2500 | loss: 4.985e-03\n",
      "SUR: UPD: it:    3000 | loss: 4.646e-03\n",
      "SUR: UPD: it:    3500 | loss: 4.486e-03\n",
      "SUR: UPD: it:    4000 | loss: 4.423e-03\n",
      "SUR: UPD: it:    4500 | loss: 4.370e-03\n",
      "SUR: UPD: it:    5000 | loss: 4.336e-03\n",
      "SUR: UPD: it:    5500 | loss: 4.299e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=0.461): it:    4000 | loss: 4.529e+01\n",
      "VI NF (t=0.502): it:    4100 | loss: 1.660e+01\n",
      "VI NF (t=0.549): it:    4200 | loss: 2.280e+01\n",
      "VI NF (t=0.600): it:    4300 | loss: 2.035e+01\n",
      "VI NF (t=0.643): it:    4400 | loss: 1.976e+01\n",
      "VI NF (t=0.700): it:    4500 | loss: 2.017e+01\n",
      "VI NF (t=0.760): it:    4600 | loss: 2.153e+01\n",
      "VI NF (t=0.854): it:    4700 | loss: 2.379e+01\n",
      "VI NF (t=0.927): it:    4800 | loss: 2.511e+01\n",
      "VI NF (t=1.000): it:    4900 | loss: 2.478e+01\n",
      "--- Saving results at iteration 5000\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "1.251e-01 -> 1.251e-01\n",
      "3.570e-01 -> 3.570e-01\n",
      "1.182e+00 -> 1.182e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 1.000e-01\n",
      "SUR: UPD: it:     500 | loss: 2.278e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.450e-02\n",
      "SUR: UPD: it:    1500 | loss: 7.963e-03\n",
      "SUR: UPD: it:    2000 | loss: 6.595e-03\n",
      "SUR: UPD: it:    2500 | loss: 5.468e-03\n",
      "SUR: UPD: it:    3000 | loss: 5.312e-03\n",
      "SUR: UPD: it:    3500 | loss: 5.179e-03\n",
      "SUR: UPD: it:    4000 | loss: 5.098e-03\n",
      "SUR: UPD: it:    4500 | loss: 5.069e-03\n",
      "SUR: UPD: it:    5000 | loss: 5.041e-03\n",
      "SUR: UPD: it:    5500 | loss: 5.022e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:    5000 | loss: 1.624e+02\n",
      "VI NF (t=1.000): it:    5100 | loss: 2.570e+01\n",
      "VI NF (t=1.000): it:    5200 | loss: 2.540e+01\n",
      "VI NF (t=1.000): it:    5300 | loss: 2.534e+01\n",
      "VI NF (t=1.000): it:    5400 | loss: 2.592e+01\n",
      "VI NF (t=1.000): it:    5500 | loss: 2.525e+01\n",
      "VI NF (t=1.000): it:    5600 | loss: 2.511e+01\n",
      "VI NF (t=1.000): it:    5700 | loss: 2.484e+01\n",
      "VI NF (t=1.000): it:    5800 | loss: 2.493e+01\n",
      "VI NF (t=1.000): it:    5900 | loss: 2.527e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "4.515e-01 -> 4.515e-01\n",
      "1.485e-02 -> 2.705e-02\n",
      "6.321e-01 -> 6.321e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 7.886e-03\n",
      "SUR: UPD: it:     500 | loss: 2.995e-02\n",
      "SUR: UPD: it:    1000 | loss: 2.758e-02\n",
      "SUR: UPD: it:    1500 | loss: 8.218e-03\n",
      "SUR: UPD: it:    2000 | loss: 5.978e-03\n",
      "SUR: UPD: it:    2500 | loss: 6.212e-03\n",
      "SUR: UPD: it:    3000 | loss: 5.762e-03\n",
      "SUR: UPD: it:    3500 | loss: 5.613e-03\n",
      "SUR: UPD: it:    4000 | loss: 5.579e-03\n",
      "SUR: UPD: it:    4500 | loss: 5.523e-03\n",
      "SUR: UPD: it:    5000 | loss: 5.494e-03\n",
      "SUR: UPD: it:    5500 | loss: 5.470e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:    6000 | loss: 2.996e+01\n",
      "VI NF (t=1.000): it:    6100 | loss: 2.469e+01\n",
      "VI NF (t=1.000): it:    6200 | loss: 2.450e+01\n",
      "VI NF (t=1.000): it:    6300 | loss: 2.475e+01\n",
      "VI NF (t=1.000): it:    6400 | loss: 2.473e+01\n",
      "VI NF (t=1.000): it:    6500 | loss: 2.448e+01\n",
      "VI NF (t=1.000): it:    6600 | loss: 2.477e+01\n",
      "VI NF (t=1.000): it:    6700 | loss: 2.464e+01\n",
      "VI NF (t=1.000): it:    6800 | loss: 2.480e+01\n",
      "VI NF (t=1.000): it:    6900 | loss: 2.448e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "3.409e-01 -> 3.409e-01\n",
      "7.840e-02 -> 1.299e-01\n",
      "6.000e-01 -> 6.000e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 5.783e-03\n",
      "SUR: UPD: it:     500 | loss: 2.647e-02\n",
      "SUR: UPD: it:    1000 | loss: 2.303e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.018e-02\n",
      "SUR: UPD: it:    2000 | loss: 7.093e-03\n",
      "SUR: UPD: it:    2500 | loss: 5.909e-03\n",
      "SUR: UPD: it:    3000 | loss: 6.542e-03\n",
      "SUR: UPD: it:    3500 | loss: 5.754e-03\n",
      "SUR: UPD: it:    4000 | loss: 5.740e-03\n",
      "SUR: UPD: it:    4500 | loss: 5.717e-03\n",
      "SUR: UPD: it:    5000 | loss: 5.704e-03\n",
      "SUR: UPD: it:    5500 | loss: 5.693e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:    7000 | loss: 2.490e+01\n",
      "VI NF (t=1.000): it:    7100 | loss: 2.483e+01\n",
      "VI NF (t=1.000): it:    7200 | loss: 2.464e+01\n",
      "VI NF (t=1.000): it:    7300 | loss: 2.491e+01\n",
      "VI NF (t=1.000): it:    7400 | loss: 2.453e+01\n",
      "VI NF (t=1.000): it:    7500 | loss: 2.460e+01\n",
      "VI NF (t=1.000): it:    7600 | loss: 2.452e+01\n",
      "VI NF (t=1.000): it:    7700 | loss: 2.446e+01\n",
      "VI NF (t=1.000): it:    7800 | loss: 2.493e+01\n",
      "VI NF (t=1.000): it:    7900 | loss: 2.479e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "2.390e-01 -> 2.390e-01\n",
      "7.343e-02 -> 2.131e-01\n",
      "4.162e-01 -> 4.162e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 6.044e-03\n",
      "SUR: UPD: it:     500 | loss: 7.658e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.753e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.912e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.157e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.061e-02\n",
      "SUR: UPD: it:    3000 | loss: 1.040e-02\n",
      "SUR: UPD: it:    3500 | loss: 1.024e-02\n",
      "SUR: UPD: it:    4000 | loss: 9.705e-03\n",
      "SUR: UPD: it:    4500 | loss: 9.524e-03\n",
      "SUR: UPD: it:    5000 | loss: 9.421e-03\n",
      "SUR: UPD: it:    5500 | loss: 9.352e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:    8000 | loss: 2.727e+01\n",
      "VI NF (t=1.000): it:    8100 | loss: 2.460e+01\n",
      "VI NF (t=1.000): it:    8200 | loss: 2.475e+01\n",
      "VI NF (t=1.000): it:    8300 | loss: 2.452e+01\n",
      "VI NF (t=1.000): it:    8400 | loss: 2.448e+01\n",
      "VI NF (t=1.000): it:    8500 | loss: 2.487e+01\n",
      "VI NF (t=1.000): it:    8600 | loss: 2.488e+01\n",
      "VI NF (t=1.000): it:    8700 | loss: 2.412e+01\n",
      "VI NF (t=1.000): it:    8800 | loss: 2.449e+01\n",
      "VI NF (t=1.000): it:    8900 | loss: 2.532e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "3.507e-01 -> 3.507e-01\n",
      "9.075e-02 -> 1.897e-01\n",
      "5.411e-01 -> 5.411e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.629e-03\n",
      "SUR: UPD: it:     500 | loss: 4.242e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.345e-02\n",
      "SUR: UPD: it:    1500 | loss: 9.400e-03\n",
      "SUR: UPD: it:    2000 | loss: 9.149e-03\n",
      "SUR: UPD: it:    2500 | loss: 8.858e-03\n",
      "SUR: UPD: it:    3000 | loss: 8.833e-03\n",
      "SUR: UPD: it:    3500 | loss: 8.496e-03\n",
      "SUR: UPD: it:    4000 | loss: 8.472e-03\n",
      "SUR: UPD: it:    4500 | loss: 8.416e-03\n",
      "SUR: UPD: it:    5000 | loss: 8.387e-03\n",
      "SUR: UPD: it:    5500 | loss: 8.367e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:    9000 | loss: 2.506e+01\n",
      "VI NF (t=1.000): it:    9100 | loss: 2.473e+01\n",
      "VI NF (t=1.000): it:    9200 | loss: 2.441e+01\n",
      "VI NF (t=1.000): it:    9300 | loss: 2.432e+01\n",
      "VI NF (t=1.000): it:    9400 | loss: 2.477e+01\n",
      "VI NF (t=1.000): it:    9500 | loss: 2.432e+01\n",
      "VI NF (t=1.000): it:    9600 | loss: 2.522e+01\n",
      "VI NF (t=1.000): it:    9700 | loss: 2.444e+01\n",
      "VI NF (t=1.000): it:    9800 | loss: 2.427e+01\n",
      "VI NF (t=1.000): it:    9900 | loss: 2.463e+01\n",
      "--- Saving results at iteration 10000\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "3.501e-02 -> 5.220e-02\n",
      "2.750e-02 -> 5.381e-02\n",
      "6.335e-02 -> 7.766e-02\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 8.515e-03\n",
      "SUR: UPD: it:     500 | loss: 7.904e-02\n",
      "SUR: UPD: it:    1000 | loss: 2.109e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.580e-02\n",
      "SUR: UPD: it:    2000 | loss: 9.979e-03\n",
      "SUR: UPD: it:    2500 | loss: 9.178e-03\n",
      "SUR: UPD: it:    3000 | loss: 8.641e-03\n",
      "SUR: UPD: it:    3500 | loss: 8.564e-03\n",
      "SUR: UPD: it:    4000 | loss: 8.385e-03\n",
      "SUR: UPD: it:    4500 | loss: 8.347e-03\n",
      "SUR: UPD: it:    5000 | loss: 8.323e-03\n",
      "SUR: UPD: it:    5500 | loss: 8.307e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   10000 | loss: 2.453e+01\n",
      "VI NF (t=1.000): it:   10100 | loss: 2.418e+01\n",
      "VI NF (t=1.000): it:   10200 | loss: 2.427e+01\n",
      "VI NF (t=1.000): it:   10300 | loss: 2.416e+01\n",
      "VI NF (t=1.000): it:   10400 | loss: 2.434e+01\n",
      "VI NF (t=1.000): it:   10500 | loss: 2.427e+01\n",
      "VI NF (t=1.000): it:   10600 | loss: 2.418e+01\n",
      "VI NF (t=1.000): it:   10700 | loss: 2.455e+01\n",
      "VI NF (t=1.000): it:   10800 | loss: 2.426e+01\n",
      "VI NF (t=1.000): it:   10900 | loss: 2.416e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "4.925e-01 -> 4.925e-01\n",
      "9.056e-02 -> 2.494e-01\n",
      "9.530e-01 -> 9.530e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 1.148e-02\n",
      "SUR: UPD: it:     500 | loss: 3.745e-02\n",
      "SUR: UPD: it:    1000 | loss: 2.433e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.256e-02\n",
      "SUR: UPD: it:    2000 | loss: 9.840e-03\n",
      "SUR: UPD: it:    2500 | loss: 9.544e-03\n",
      "SUR: UPD: it:    3000 | loss: 9.461e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.103e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.054e-03\n",
      "SUR: UPD: it:    4500 | loss: 8.943e-03\n",
      "SUR: UPD: it:    5000 | loss: 8.916e-03\n",
      "SUR: UPD: it:    5500 | loss: 8.900e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   11000 | loss: 2.566e+01\n",
      "VI NF (t=1.000): it:   11100 | loss: 2.417e+01\n",
      "VI NF (t=1.000): it:   11200 | loss: 2.426e+01\n",
      "VI NF (t=1.000): it:   11300 | loss: 2.423e+01\n",
      "VI NF (t=1.000): it:   11400 | loss: 2.402e+01\n",
      "VI NF (t=1.000): it:   11500 | loss: 2.393e+01\n",
      "VI NF (t=1.000): it:   11600 | loss: 2.404e+01\n",
      "VI NF (t=1.000): it:   11700 | loss: 2.390e+01\n",
      "VI NF (t=1.000): it:   11800 | loss: 2.420e+01\n",
      "VI NF (t=1.000): it:   11900 | loss: 2.405e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "4.175e-01 -> 4.175e-01\n",
      "7.052e-02 -> 4.302e-02\n",
      "6.004e-01 -> 6.004e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.111e-03\n",
      "SUR: UPD: it:     500 | loss: 4.370e-02\n",
      "SUR: UPD: it:    1000 | loss: 3.337e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.054e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.098e-02\n",
      "SUR: UPD: it:    2500 | loss: 9.204e-03\n",
      "SUR: UPD: it:    3000 | loss: 9.239e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.153e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.005e-03\n",
      "SUR: UPD: it:    4500 | loss: 8.989e-03\n",
      "SUR: UPD: it:    5000 | loss: 8.934e-03\n",
      "SUR: UPD: it:    5500 | loss: 8.919e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   12000 | loss: 2.409e+01\n",
      "VI NF (t=1.000): it:   12100 | loss: 2.409e+01\n",
      "VI NF (t=1.000): it:   12200 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   12300 | loss: 2.408e+01\n",
      "VI NF (t=1.000): it:   12400 | loss: 2.393e+01\n",
      "VI NF (t=1.000): it:   12500 | loss: 2.397e+01\n",
      "VI NF (t=1.000): it:   12600 | loss: 2.417e+01\n",
      "VI NF (t=1.000): it:   12700 | loss: 2.405e+01\n",
      "VI NF (t=1.000): it:   12800 | loss: 2.384e+01\n",
      "VI NF (t=1.000): it:   12900 | loss: 2.389e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "9.209e-01 -> 9.209e-01\n",
      "3.072e-01 -> 3.072e-01\n",
      "1.742e+00 -> 1.742e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.616e-03\n",
      "SUR: UPD: it:     500 | loss: 2.220e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.949e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.082e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.014e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.010e-02\n",
      "SUR: UPD: it:    3000 | loss: 9.833e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.616e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.542e-03\n",
      "SUR: UPD: it:    4500 | loss: 9.498e-03\n",
      "SUR: UPD: it:    5000 | loss: 9.450e-03\n",
      "SUR: UPD: it:    5500 | loss: 9.424e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   13000 | loss: 2.575e+01\n",
      "VI NF (t=1.000): it:   13100 | loss: 2.443e+01\n",
      "VI NF (t=1.000): it:   13200 | loss: 2.386e+01\n",
      "VI NF (t=1.000): it:   13300 | loss: 2.416e+01\n",
      "VI NF (t=1.000): it:   13400 | loss: 2.433e+01\n",
      "VI NF (t=1.000): it:   13500 | loss: 2.417e+01\n",
      "VI NF (t=1.000): it:   13600 | loss: 2.417e+01\n",
      "VI NF (t=1.000): it:   13700 | loss: 2.429e+01\n",
      "VI NF (t=1.000): it:   13800 | loss: 2.407e+01\n",
      "VI NF (t=1.000): it:   13900 | loss: 2.423e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "3.293e-02 -> 1.275e-01\n",
      "2.679e-02 -> 7.087e-02\n",
      "1.575e-01 -> 1.575e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.351e-03\n",
      "SUR: UPD: it:     500 | loss: 2.375e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.320e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.650e-02\n",
      "SUR: UPD: it:    2000 | loss: 9.715e-03\n",
      "SUR: UPD: it:    2500 | loss: 9.781e-03\n",
      "SUR: UPD: it:    3000 | loss: 9.570e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.526e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.345e-03\n",
      "SUR: UPD: it:    4500 | loss: 9.315e-03\n",
      "SUR: UPD: it:    5000 | loss: 9.287e-03\n",
      "SUR: UPD: it:    5500 | loss: 9.271e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   14000 | loss: 2.408e+01\n",
      "VI NF (t=1.000): it:   14100 | loss: 2.430e+01\n",
      "VI NF (t=1.000): it:   14200 | loss: 2.397e+01\n",
      "VI NF (t=1.000): it:   14300 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   14400 | loss: 2.387e+01\n",
      "VI NF (t=1.000): it:   14500 | loss: 2.423e+01\n",
      "VI NF (t=1.000): it:   14600 | loss: 2.402e+01\n",
      "VI NF (t=1.000): it:   14700 | loss: 2.440e+01\n",
      "VI NF (t=1.000): it:   14800 | loss: 2.388e+01\n",
      "VI NF (t=1.000): it:   14900 | loss: 2.411e+01\n",
      "--- Saving results at iteration 15000\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "8.749e-01 -> 8.749e-01\n",
      "2.870e-01 -> 2.870e-01\n",
      "1.527e+00 -> 1.527e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.199e-03\n",
      "SUR: UPD: it:     500 | loss: 1.859e-02\n",
      "SUR: UPD: it:    1000 | loss: 5.639e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.574e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.202e-02\n",
      "SUR: UPD: it:    2500 | loss: 9.759e-03\n",
      "SUR: UPD: it:    3000 | loss: 9.491e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.240e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.215e-03\n",
      "SUR: UPD: it:    4500 | loss: 9.155e-03\n",
      "SUR: UPD: it:    5000 | loss: 9.130e-03\n",
      "SUR: UPD: it:    5500 | loss: 9.104e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   15000 | loss: 2.391e+01\n",
      "VI NF (t=1.000): it:   15100 | loss: 2.467e+01\n",
      "VI NF (t=1.000): it:   15200 | loss: 2.385e+01\n",
      "VI NF (t=1.000): it:   15300 | loss: 2.429e+01\n",
      "VI NF (t=1.000): it:   15400 | loss: 2.411e+01\n",
      "VI NF (t=1.000): it:   15500 | loss: 2.411e+01\n",
      "VI NF (t=1.000): it:   15600 | loss: 2.395e+01\n",
      "VI NF (t=1.000): it:   15700 | loss: 2.398e+01\n",
      "VI NF (t=1.000): it:   15800 | loss: 2.406e+01\n",
      "VI NF (t=1.000): it:   15900 | loss: 2.441e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "5.331e-01 -> 5.331e-01\n",
      "2.437e-01 -> 2.437e-01\n",
      "8.560e-01 -> 8.560e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.355e-03\n",
      "SUR: UPD: it:     500 | loss: 3.445e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.701e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.385e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.044e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.034e-02\n",
      "SUR: UPD: it:    3000 | loss: 9.924e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.453e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.221e-03\n",
      "SUR: UPD: it:    4500 | loss: 9.110e-03\n",
      "SUR: UPD: it:    5000 | loss: 9.076e-03\n",
      "SUR: UPD: it:    5500 | loss: 9.035e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   16000 | loss: 2.433e+01\n",
      "VI NF (t=1.000): it:   16100 | loss: 2.384e+01\n",
      "VI NF (t=1.000): it:   16200 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   16300 | loss: 2.383e+01\n",
      "VI NF (t=1.000): it:   16400 | loss: 2.411e+01\n",
      "VI NF (t=1.000): it:   16500 | loss: 2.399e+01\n",
      "VI NF (t=1.000): it:   16600 | loss: 2.399e+01\n",
      "VI NF (t=1.000): it:   16700 | loss: 2.400e+01\n",
      "VI NF (t=1.000): it:   16800 | loss: 2.429e+01\n",
      "VI NF (t=1.000): it:   16900 | loss: 2.367e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "8.741e-01 -> 8.741e-01\n",
      "1.480e-01 -> 1.480e-01\n",
      "1.479e+00 -> 1.479e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.295e-03\n",
      "SUR: UPD: it:     500 | loss: 5.603e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.943e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.839e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.238e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.138e-02\n",
      "SUR: UPD: it:    3000 | loss: 9.483e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.123e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.009e-03\n",
      "SUR: UPD: it:    4500 | loss: 8.992e-03\n",
      "SUR: UPD: it:    5000 | loss: 8.933e-03\n",
      "SUR: UPD: it:    5500 | loss: 8.882e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   17000 | loss: 2.401e+01\n",
      "VI NF (t=1.000): it:   17100 | loss: 2.396e+01\n",
      "VI NF (t=1.000): it:   17200 | loss: 2.391e+01\n",
      "VI NF (t=1.000): it:   17300 | loss: 2.368e+01\n",
      "VI NF (t=1.000): it:   17400 | loss: 2.382e+01\n",
      "VI NF (t=1.000): it:   17500 | loss: 2.397e+01\n",
      "VI NF (t=1.000): it:   17600 | loss: 2.408e+01\n",
      "VI NF (t=1.000): it:   17700 | loss: 2.375e+01\n",
      "VI NF (t=1.000): it:   17800 | loss: 2.365e+01\n",
      "VI NF (t=1.000): it:   17900 | loss: 2.393e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "8.793e-01 -> 8.793e-01\n",
      "2.799e-01 -> 2.799e-01\n",
      "1.350e+00 -> 1.350e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 8.734e-03\n",
      "SUR: UPD: it:     500 | loss: 2.711e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.906e-02\n",
      "SUR: UPD: it:    1500 | loss: 9.741e-03\n",
      "SUR: UPD: it:    2000 | loss: 1.294e-02\n",
      "SUR: UPD: it:    2500 | loss: 9.273e-03\n",
      "SUR: UPD: it:    3000 | loss: 8.685e-03\n",
      "SUR: UPD: it:    3500 | loss: 8.546e-03\n",
      "SUR: UPD: it:    4000 | loss: 8.455e-03\n",
      "SUR: UPD: it:    4500 | loss: 8.473e-03\n",
      "SUR: UPD: it:    5000 | loss: 8.387e-03\n",
      "SUR: UPD: it:    5500 | loss: 8.368e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   18000 | loss: 2.383e+01\n",
      "VI NF (t=1.000): it:   18100 | loss: 2.375e+01\n",
      "VI NF (t=1.000): it:   18200 | loss: 2.368e+01\n",
      "VI NF (t=1.000): it:   18300 | loss: 2.419e+01\n",
      "VI NF (t=1.000): it:   18400 | loss: 2.380e+01\n",
      "VI NF (t=1.000): it:   18500 | loss: 2.381e+01\n",
      "VI NF (t=1.000): it:   18600 | loss: 2.362e+01\n",
      "VI NF (t=1.000): it:   18700 | loss: 2.381e+01\n",
      "VI NF (t=1.000): it:   18800 | loss: 2.420e+01\n",
      "VI NF (t=1.000): it:   18900 | loss: 2.391e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "2.667e-01 -> 2.667e-01\n",
      "9.823e-03 -> 1.066e-02\n",
      "5.219e-01 -> 5.219e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 8.430e-03\n",
      "SUR: UPD: it:     500 | loss: 2.583e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.394e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.364e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.000e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.036e-02\n",
      "SUR: UPD: it:    3000 | loss: 8.749e-03\n",
      "SUR: UPD: it:    3500 | loss: 8.662e-03\n",
      "SUR: UPD: it:    4000 | loss: 8.562e-03\n",
      "SUR: UPD: it:    4500 | loss: 8.476e-03\n",
      "SUR: UPD: it:    5000 | loss: 8.445e-03\n",
      "SUR: UPD: it:    5500 | loss: 8.428e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   19000 | loss: 2.401e+01\n",
      "VI NF (t=1.000): it:   19100 | loss: 2.381e+01\n",
      "VI NF (t=1.000): it:   19200 | loss: 2.388e+01\n",
      "VI NF (t=1.000): it:   19300 | loss: 2.402e+01\n",
      "VI NF (t=1.000): it:   19400 | loss: 2.407e+01\n",
      "VI NF (t=1.000): it:   19500 | loss: 2.396e+01\n",
      "VI NF (t=1.000): it:   19600 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   19700 | loss: 2.375e+01\n",
      "VI NF (t=1.000): it:   19800 | loss: 2.396e+01\n",
      "VI NF (t=1.000): it:   19900 | loss: 2.364e+01\n",
      "--- Saving results at iteration 20000\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "7.830e-02 -> 1.945e-01\n",
      "4.140e-02 -> 6.283e-03\n",
      "1.750e-01 -> 1.750e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.128e-03\n",
      "SUR: UPD: it:     500 | loss: 5.586e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.969e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.434e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.171e-02\n",
      "SUR: UPD: it:    2500 | loss: 9.920e-03\n",
      "SUR: UPD: it:    3000 | loss: 9.691e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.472e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.475e-03\n",
      "SUR: UPD: it:    4500 | loss: 9.437e-03\n",
      "SUR: UPD: it:    5000 | loss: 9.409e-03\n",
      "SUR: UPD: it:    5500 | loss: 9.403e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   20000 | loss: 2.513e+01\n",
      "VI NF (t=1.000): it:   20100 | loss: 2.411e+01\n",
      "VI NF (t=1.000): it:   20200 | loss: 2.391e+01\n",
      "VI NF (t=1.000): it:   20300 | loss: 2.388e+01\n",
      "VI NF (t=1.000): it:   20400 | loss: 2.421e+01\n",
      "VI NF (t=1.000): it:   20500 | loss: 2.406e+01\n",
      "VI NF (t=1.000): it:   20600 | loss: 2.376e+01\n",
      "VI NF (t=1.000): it:   20700 | loss: 2.378e+01\n",
      "VI NF (t=1.000): it:   20800 | loss: 2.405e+01\n",
      "VI NF (t=1.000): it:   20900 | loss: 2.393e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "2.851e-01 -> 2.851e-01\n",
      "6.349e-03 -> 6.309e-02\n",
      "3.373e-01 -> 3.373e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 1.055e-02\n",
      "SUR: UPD: it:     500 | loss: 3.019e-02\n",
      "SUR: UPD: it:    1000 | loss: 1.422e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.338e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.238e-02\n",
      "SUR: UPD: it:    2500 | loss: 9.835e-03\n",
      "SUR: UPD: it:    3000 | loss: 9.416e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.168e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.004e-03\n",
      "SUR: UPD: it:    4500 | loss: 8.917e-03\n",
      "SUR: UPD: it:    5000 | loss: 8.896e-03\n",
      "SUR: UPD: it:    5500 | loss: 8.863e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   21000 | loss: 2.430e+01\n",
      "VI NF (t=1.000): it:   21100 | loss: 2.415e+01\n",
      "VI NF (t=1.000): it:   21200 | loss: 2.372e+01\n",
      "VI NF (t=1.000): it:   21300 | loss: 2.395e+01\n",
      "VI NF (t=1.000): it:   21400 | loss: 2.402e+01\n",
      "VI NF (t=1.000): it:   21500 | loss: 2.363e+01\n",
      "VI NF (t=1.000): it:   21600 | loss: 2.382e+01\n",
      "VI NF (t=1.000): it:   21700 | loss: 2.380e+01\n",
      "VI NF (t=1.000): it:   21800 | loss: 2.395e+01\n",
      "VI NF (t=1.000): it:   21900 | loss: 2.381e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "1.327e+00 -> 1.327e+00\n",
      "4.394e-01 -> 4.394e-01\n",
      "2.329e+00 -> 2.329e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.883e-03\n",
      "SUR: UPD: it:     500 | loss: 4.144e-02\n",
      "SUR: UPD: it:    1000 | loss: 2.172e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.453e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.272e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.099e-02\n",
      "SUR: UPD: it:    3000 | loss: 1.024e-02\n",
      "SUR: UPD: it:    3500 | loss: 1.010e-02\n",
      "SUR: UPD: it:    4000 | loss: 1.004e-02\n",
      "SUR: UPD: it:    4500 | loss: 9.949e-03\n",
      "SUR: UPD: it:    5000 | loss: 9.930e-03\n",
      "SUR: UPD: it:    5500 | loss: 9.918e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   22000 | loss: 2.528e+01\n",
      "VI NF (t=1.000): it:   22100 | loss: 2.387e+01\n",
      "VI NF (t=1.000): it:   22200 | loss: 2.379e+01\n",
      "VI NF (t=1.000): it:   22300 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   22400 | loss: 2.434e+01\n",
      "VI NF (t=1.000): it:   22500 | loss: 2.386e+01\n",
      "VI NF (t=1.000): it:   22600 | loss: 2.390e+01\n",
      "VI NF (t=1.000): it:   22700 | loss: 2.401e+01\n",
      "VI NF (t=1.000): it:   22800 | loss: 2.396e+01\n",
      "VI NF (t=1.000): it:   22900 | loss: 2.375e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "1.464e+00 -> 1.464e+00\n",
      "3.185e-01 -> 3.185e-01\n",
      "2.434e+00 -> 2.434e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 1.823e-02\n",
      "SUR: UPD: it:     500 | loss: 4.369e-02\n",
      "SUR: UPD: it:    1000 | loss: 2.707e-02\n",
      "SUR: UPD: it:    1500 | loss: 1.524e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.061e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.015e-02\n",
      "SUR: UPD: it:    3000 | loss: 9.985e-03\n",
      "SUR: UPD: it:    3500 | loss: 9.877e-03\n",
      "SUR: UPD: it:    4000 | loss: 9.779e-03\n",
      "SUR: UPD: it:    4500 | loss: 9.640e-03\n",
      "SUR: UPD: it:    5000 | loss: 9.616e-03\n",
      "SUR: UPD: it:    5500 | loss: 9.603e-03\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   23000 | loss: 2.554e+01\n",
      "VI NF (t=1.000): it:   23100 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   23200 | loss: 2.399e+01\n",
      "VI NF (t=1.000): it:   23300 | loss: 2.398e+01\n",
      "VI NF (t=1.000): it:   23400 | loss: 2.399e+01\n",
      "VI NF (t=1.000): it:   23500 | loss: 2.394e+01\n",
      "VI NF (t=1.000): it:   23600 | loss: 2.367e+01\n",
      "VI NF (t=1.000): it:   23700 | loss: 2.401e+01\n",
      "VI NF (t=1.000): it:   23800 | loss: 2.392e+01\n",
      "VI NF (t=1.000): it:   23900 | loss: 2.390e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "2.651e-01 -> 2.651e-01\n",
      "5.581e-03 -> 9.331e-02\n",
      "4.532e-01 -> 4.532e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 9.721e-03\n",
      "SUR: UPD: it:     500 | loss: 7.374e-02\n",
      "SUR: UPD: it:    1000 | loss: 3.779e-02\n",
      "SUR: UPD: it:    1500 | loss: 3.504e-02\n",
      "SUR: UPD: it:    2000 | loss: 2.774e-02\n",
      "SUR: UPD: it:    2500 | loss: 2.436e-02\n",
      "SUR: UPD: it:    3000 | loss: 2.420e-02\n",
      "SUR: UPD: it:    3500 | loss: 2.402e-02\n",
      "SUR: UPD: it:    4000 | loss: 2.391e-02\n",
      "SUR: UPD: it:    4500 | loss: 2.384e-02\n",
      "SUR: UPD: it:    5000 | loss: 2.381e-02\n",
      "SUR: UPD: it:    5500 | loss: 2.380e-02\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   24000 | loss: 2.451e+01\n",
      "VI NF (t=1.000): it:   24100 | loss: 2.421e+01\n",
      "VI NF (t=1.000): it:   24200 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   24300 | loss: 2.407e+01\n",
      "VI NF (t=1.000): it:   24400 | loss: 2.391e+01\n",
      "VI NF (t=1.000): it:   24500 | loss: 2.404e+01\n",
      "VI NF (t=1.000): it:   24600 | loss: 2.400e+01\n",
      "VI NF (t=1.000): it:   24700 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   24800 | loss: 2.393e+01\n",
      "VI NF (t=1.000): it:   24900 | loss: 2.389e+01\n",
      "--- Saving results at iteration 25000\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "1.094e-01 -> 1.094e-01\n",
      "1.681e-02 -> 1.561e-02\n",
      "2.576e-01 -> 2.576e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 2.357e-02\n",
      "SUR: UPD: it:     500 | loss: 6.962e-02\n",
      "SUR: UPD: it:    1000 | loss: 5.116e-02\n",
      "SUR: UPD: it:    1500 | loss: 3.484e-02\n",
      "SUR: UPD: it:    2000 | loss: 3.324e-02\n",
      "SUR: UPD: it:    2500 | loss: 3.041e-02\n",
      "SUR: UPD: it:    3000 | loss: 2.997e-02\n",
      "SUR: UPD: it:    3500 | loss: 2.965e-02\n",
      "SUR: UPD: it:    4000 | loss: 2.940e-02\n",
      "SUR: UPD: it:    4500 | loss: 2.930e-02\n",
      "SUR: UPD: it:    5000 | loss: 2.921e-02\n",
      "SUR: UPD: it:    5500 | loss: 2.915e-02\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   25000 | loss: 2.426e+01\n",
      "VI NF (t=1.000): it:   25100 | loss: 2.418e+01\n",
      "VI NF (t=1.000): it:   25200 | loss: 2.410e+01\n",
      "VI NF (t=1.000): it:   25300 | loss: 2.427e+01\n",
      "VI NF (t=1.000): it:   25400 | loss: 2.422e+01\n",
      "VI NF (t=1.000): it:   25500 | loss: 2.425e+01\n",
      "VI NF (t=1.000): it:   25600 | loss: 2.439e+01\n",
      "VI NF (t=1.000): it:   25700 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   25800 | loss: 2.432e+01\n",
      "VI NF (t=1.000): it:   25900 | loss: 2.401e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "4.243e-01 -> 4.243e-01\n",
      "1.865e-01 -> 1.865e-01\n",
      "7.046e-01 -> 7.046e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 2.886e-02\n",
      "SUR: UPD: it:     500 | loss: 7.227e-02\n",
      "SUR: UPD: it:    1000 | loss: 4.505e-02\n",
      "SUR: UPD: it:    1500 | loss: 3.233e-02\n",
      "SUR: UPD: it:    2000 | loss: 2.860e-02\n",
      "SUR: UPD: it:    2500 | loss: 2.693e-02\n",
      "SUR: UPD: it:    3000 | loss: 2.654e-02\n",
      "SUR: UPD: it:    3500 | loss: 2.644e-02\n",
      "SUR: UPD: it:    4000 | loss: 2.627e-02\n",
      "SUR: UPD: it:    4500 | loss: 2.621e-02\n",
      "SUR: UPD: it:    5000 | loss: 2.616e-02\n",
      "SUR: UPD: it:    5500 | loss: 2.613e-02\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   26000 | loss: 2.598e+01\n",
      "VI NF (t=1.000): it:   26100 | loss: 2.487e+01\n",
      "VI NF (t=1.000): it:   26200 | loss: 2.410e+01\n",
      "VI NF (t=1.000): it:   26300 | loss: 2.439e+01\n",
      "VI NF (t=1.000): it:   26400 | loss: 2.433e+01\n",
      "VI NF (t=1.000): it:   26500 | loss: 2.431e+01\n",
      "VI NF (t=1.000): it:   26600 | loss: 2.432e+01\n",
      "VI NF (t=1.000): it:   26700 | loss: 2.434e+01\n",
      "VI NF (t=1.000): it:   26800 | loss: 2.443e+01\n",
      "VI NF (t=1.000): it:   26900 | loss: 2.423e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "6.479e-01 -> 6.479e-01\n",
      "2.321e-01 -> 2.321e-01\n",
      "9.787e-01 -> 9.787e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 2.604e-02\n",
      "SUR: UPD: it:     500 | loss: 5.884e-02\n",
      "SUR: UPD: it:    1000 | loss: 4.277e-02\n",
      "SUR: UPD: it:    1500 | loss: 3.187e-02\n",
      "SUR: UPD: it:    2000 | loss: 2.454e-02\n",
      "SUR: UPD: it:    2500 | loss: 2.328e-02\n",
      "SUR: UPD: it:    3000 | loss: 2.254e-02\n",
      "SUR: UPD: it:    3500 | loss: 2.221e-02\n",
      "SUR: UPD: it:    4000 | loss: 2.199e-02\n",
      "SUR: UPD: it:    4500 | loss: 2.184e-02\n",
      "SUR: UPD: it:    5000 | loss: 2.174e-02\n",
      "SUR: UPD: it:    5500 | loss: 2.167e-02\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   27000 | loss: 2.509e+01\n",
      "VI NF (t=1.000): it:   27100 | loss: 2.467e+01\n",
      "VI NF (t=1.000): it:   27200 | loss: 2.456e+01\n",
      "VI NF (t=1.000): it:   27300 | loss: 2.446e+01\n",
      "VI NF (t=1.000): it:   27400 | loss: 2.439e+01\n",
      "VI NF (t=1.000): it:   27500 | loss: 2.494e+01\n",
      "VI NF (t=1.000): it:   27600 | loss: 2.451e+01\n",
      "VI NF (t=1.000): it:   27700 | loss: 2.467e+01\n",
      "VI NF (t=1.000): it:   27800 | loss: 2.473e+01\n",
      "VI NF (t=1.000): it:   27900 | loss: 2.445e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "1.008e+00 -> 1.008e+00\n",
      "1.046e-01 -> 1.046e-01\n",
      "1.840e+00 -> 1.840e+00\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 2.142e-02\n",
      "SUR: UPD: it:     500 | loss: 6.075e-02\n",
      "SUR: UPD: it:    1000 | loss: 3.656e-02\n",
      "SUR: UPD: it:    1500 | loss: 2.359e-02\n",
      "SUR: UPD: it:    2000 | loss: 2.064e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.793e-02\n",
      "SUR: UPD: it:    3000 | loss: 1.756e-02\n",
      "SUR: UPD: it:    3500 | loss: 1.708e-02\n",
      "SUR: UPD: it:    4000 | loss: 1.699e-02\n",
      "SUR: UPD: it:    4500 | loss: 1.695e-02\n",
      "SUR: UPD: it:    5000 | loss: 1.693e-02\n",
      "SUR: UPD: it:    5500 | loss: 1.692e-02\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   28000 | loss: 2.551e+01\n",
      "VI NF (t=1.000): it:   28100 | loss: 2.417e+01\n",
      "VI NF (t=1.000): it:   28200 | loss: 2.402e+01\n",
      "VI NF (t=1.000): it:   28300 | loss: 2.391e+01\n",
      "VI NF (t=1.000): it:   28400 | loss: 2.405e+01\n",
      "VI NF (t=1.000): it:   28500 | loss: 2.406e+01\n",
      "VI NF (t=1.000): it:   28600 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   28700 | loss: 2.409e+01\n",
      "VI NF (t=1.000): it:   28800 | loss: 2.394e+01\n",
      "VI NF (t=1.000): it:   28900 | loss: 2.415e+01\n",
      "\n",
      "--- Updating surrogate model\n",
      "\n",
      "Std before inflation -> Std after inflation\n",
      "1.621e-01 -> 1.621e-01\n",
      "1.489e-02 -> 6.509e-02\n",
      "3.233e-01 -> 3.233e-01\n",
      "\n",
      "SUR: UPD: it:       0 | loss: 1.702e-02\n",
      "SUR: UPD: it:     500 | loss: 8.995e-02\n",
      "SUR: UPD: it:    1000 | loss: 2.719e-02\n",
      "SUR: UPD: it:    1500 | loss: 2.149e-02\n",
      "SUR: UPD: it:    2000 | loss: 1.759e-02\n",
      "SUR: UPD: it:    2500 | loss: 1.725e-02\n",
      "SUR: UPD: it:    3000 | loss: 1.621e-02\n",
      "SUR: UPD: it:    3500 | loss: 1.621e-02\n",
      "SUR: UPD: it:    4000 | loss: 1.600e-02\n",
      "SUR: UPD: it:    4500 | loss: 1.596e-02\n",
      "SUR: UPD: it:    5000 | loss: 1.593e-02\n",
      "SUR: UPD: it:    5500 | loss: 1.592e-02\n",
      "\n",
      "--- Surrogate model updated\n",
      "\n",
      "VI NF (t=1.000): it:   29000 | loss: 2.414e+01\n",
      "VI NF (t=1.000): it:   29100 | loss: 2.417e+01\n",
      "VI NF (t=1.000): it:   29200 | loss: 2.420e+01\n",
      "VI NF (t=1.000): it:   29300 | loss: 2.423e+01\n",
      "VI NF (t=1.000): it:   29400 | loss: 2.395e+01\n",
      "VI NF (t=1.000): it:   29500 | loss: 2.416e+01\n",
      "VI NF (t=1.000): it:   29600 | loss: 2.380e+01\n",
      "VI NF (t=1.000): it:   29700 | loss: 2.413e+01\n",
      "VI NF (t=1.000): it:   29800 | loss: 2.404e+01\n",
      "\n",
      "--- Simulation completed!\n"
     ]
    }
   ],
   "source": [
    "## Run \n",
    "print('')\n",
    "print('--- TUTORIAL: Ballistic Example - with NN surrogate and annealing')\n",
    "\n",
    "# Assign logdensity\n",
    "exp.model_logdensity = lambda x: log_density(x, model, exp.surrogate, trsf)\n",
    "\n",
    "# Run VI\n",
    "exp.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1db890af",
   "metadata": {},
   "source": [
    "We generate plots with the same command we used for full model inference, but a different folder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "10bb6904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting log...\n",
      "Plotting posterior samples...\n",
      "Plotting posterior predictive samples...\n"
     ]
    }
   ],
   "source": [
    "import linfa\n",
    "! python3 -m linfa.plot_res -n phys_surr_3d -i 25000 -f \"./\" -p 'png' -d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63dcbf7a",
   "metadata": {},
   "source": [
    "You can now visualize the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6541105d",
   "metadata": {},
   "source": [
    "<center><img src=\"./phys_surr_3d/log_plot.png\" width=300 /></center></br>\n",
    "\n",
    "<center> <b>Figure:</b> Loss profile</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d950d869",
   "metadata": {},
   "source": [
    "<center><img src=\"phys_surr_3d/data_plot_phys_surr_3d_25000_0_1.png\" width=400></img>\n",
    "<img src=\"phys_surr_3d/data_plot_phys_surr_3d_25000_0_2.png\" width=400></img>\n",
    "<img src=\"phys_surr_3d/data_plot_phys_surr_3d_25000_1_2.png\" width=400></img></center></br>\n",
    "\n",
    "<center> <b>Figure:</b> Two-dimensional slices from the predictive posterior distribution.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe668055",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./phys_surr 3d/params_plot_phys_surr_3d_25000_0_1.png\" width=400></img>\n",
    "<img src=\"./phys_surr_3d/params_plot_phys_surr_3d_25000_0_2.png\" width=400></img>\n",
    "<img src=\"./phys_surr_3d/params_plot_phys_surr_3d_25000_1_2.png\" width=400></img>\n",
    "</center></br>\n",
    "\n",
    "<center> <b>Figure:</b> Two-dimensional slices from posterior distribution.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "440c581f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
